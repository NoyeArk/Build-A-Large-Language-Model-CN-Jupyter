{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75cd44c",
   "metadata": {},
   "source": [
    "# 7. 指令遵循微调\n",
    "\n",
    "本章涵盖以下内容：\n",
    "\n",
    "+ **LLM 指令微调过程概述**\n",
    "+ **为监督式指令微调准备数据集**\n",
    "+ **批量组织指令数据**\n",
    "+ **评估 LLM 通过指令遵循生成的内容质量**\n",
    "+ **评估一个经过指令微调的 LLM**\n",
    "\n",
    "-----\n",
    "\n",
    "- [7.1 指令遵循微调简介](#71-指令遵循微调简介)\n",
    "- [7.2 为监督指令微调准备数据集](#72-为监督指令微调准备数据集)\n",
    "- [7.3 将数据组织成训练批次](#73-将数据组织成训练批次)\n",
    "- [7.4 为指令数据集创建数据加载器](#74-为指令数据集创建数据加载器)\n",
    "- [7.5 加载预训练的 LLM](#75-加载预训练的-llm)\n",
    "- [7.6 指令微调 LLM](#76-指令微调-llm)\n",
    "- [7.7 提取并保存响应](#77-提取并保存响应)\n",
    "- [7.8 评估指令微调后的 LLM](#78-评估指令微调后的-llm)\n",
    "- [7.9 结语](#79-结语)\n",
    "  - [7.9.1 接下来如何做？](#791-接下来如何做)\n",
    "  - [7.9.2 如何在快速变化的前沿领域中保持领先](#792-如何在快速变化的前沿领域中保持领先)\n",
    "- [7.10 本章摘要](#710-本章摘要)\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "\n",
    "在之前的章节中，我们实现了 LLM 架构，完成了预训练，并将外部的预训练权重导入模型。接着，在上一章中，我们专注于对 LLM 进行特定分类任务的微调，即区分出正常短信和垃圾短信。在本章中，我们将介绍如何微调 LLM 以遵循人类指令（见图 7.1），这是开发用于聊天机器人、个人助理和其他对话任务的 LLM 的主要技术之一。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.1.png\" width=\"75%\" />\n",
    "\n",
    "图 7.1 展示了微调 LLM 的两种主要方式：用于分类任务的微调（步骤 8）和用于指令遵循的微调（步骤 9）。上一章中我们已实现了步骤 8，本章将重点讲解如何使用指令数据集微调 LLM，具体过程将在下一节进一步说明。\n",
    "\n",
    "\n",
    "\n",
    "## 7.1 指令遵循微调简介\n",
    "\n",
    "我们在第 5 章中已了解到对 LLM 的预训练是一种逐词生成的学习过程。预训练后，LLM 将具备根据输入片段补全文本的能力，可以完成句子或生成段落。\n",
    "\n",
    "然而，预训练的 LLM 在处理如“修正该文本的语法”或“将该文本转换为被动语态”等特定指令时往往表现不佳。我们将在第 7.5 节中详细讨论一个具体示例，演示如何加载预训练模型并基于其进行指令微调。\n",
    "\n",
    "本章将专注于提升 LLM 遵循指令并生成理想回答的能力，如图 7.2 所示。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.2.png\" width=\"75%\" />\n",
    "\n",
    "在本章的剩余部分，我们将逐步实现指令微调过程，首先从数据集准备开始，如图 7.3 所示。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.3.png\" width=\"75%\" />\n",
    "\n",
    "数据集准备是指令微调中的关键环节，本章的大部分内容都将围绕这一过程展开。下一节将开始实现下载和格式化数据集的代码，这是数据集准备过程的第一步（如图 7.3 所示）。\n",
    "\n",
    "---\n",
    "\n",
    "## 7.2 为监督指令微调准备数据集\n",
    "\n",
    "在本节中，我们将下载并格式化指令数据集，以便对预训练的 LLM 进行指令微调。该数据集包含 1100 组指令-响应对，类似于图 7.2 中所示的示例。该数据集专为本书创建，有兴趣的读者可以在附录 B 中找到其他公开的指令数据集。\n",
    "\n",
    "以下代码通过实现并执行一个函数来下载这个数据集。该数据集体积较小（仅 204 KB），采用 JSON 格式，其结构与 Python 字典类似，便于人类阅读和机器处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1abfa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "# Listing 7.1 Downloading the dataset\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else: #A\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"../data/instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_mainchapter-code/instruction-data.json\"\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bede0a7",
   "metadata": {},
   "source": [
    "可以看到，我们从 JSON 文件中加载的‘数据列表’包含 1100 条指令数据集记录。让我们打印其中一条记录，看看每条记录的结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa55f2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3189444",
   "metadata": {},
   "source": [
    "如我们所见，打印出的记录是一个包含 'instruction'、'input' 和 'output' 键值的 Python 字典对象。我们来看另一条记录：\n",
    "\n",
    "\n",
    "根据该记录的内容，‘input’ 字段可能偶尔为空。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab787e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095c8ba",
   "metadata": {},
   "source": [
    "指令微调（instruction finetuning），也称为监督式指令微调（supervised instruction finetuning），是指在包含明确输入-输出对的数据集上对模型进行训练（例如从 JSON 文件中提取的输入-输出对）。在为大语言模型（LLM）格式化这些条目时，通常会使用多种不同的方法。图 7.4 展示了两种不同的示例格式（通常称为提示风格），这些格式常用于训练一些知名的 LLM，例如 Alpaca 和 Phi-3。Alpaca 是最早公开指令微调过程的 LLM 之一，而由微软开发的 Phi-3 则展示了提示风格的多样性。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.4.png\" width=\"75%\" />\n",
    "\n",
    "本章其余部分将使用 Alpaca 风格的提示方式，这是最受欢迎的提示风格之一，主要是因为它帮助定义了最初的微调方法。\n",
    "\n",
    "> **练习 7.1 改变提示词风格**\n",
    ">\n",
    "> 在使用 Alpaca 提示语风格对模型进行微调之后，尝试图 7.4 中展示的 Phi-3 提示语风格，并观察其是否会影响模型的响应效果。\n",
    "\n",
    "我们首先定义一个`format_input`函数，用于将数据列表中的条目转换为如图 7.4 所示的 Alpaca 风格输入格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9d2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 7.2 Implementing the prompt formatting function\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1219e",
   "metadata": {},
   "source": [
    "`format_input` 函数接受一个字典条目作为输入，并构建格式化字符串。我们来用之前查看过的数据集条目 `data[50]` 测试一下这个函数的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3bd75bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de87673",
   "metadata": {},
   "source": [
    "请注意，当 'input' 字段为空时，`format_input`函数会跳过可选的 '### Input:' 部分。我们可以通过将`format_input`函数应用于之前检查过的数据项 data[999] 来测试这一点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99be9403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bf020",
   "metadata": {},
   "source": [
    "在进入下一节的 PyTorch 数据加载器设置之前，先将数据集划分为训练集、验证集和测试集，这与我们在上一章处理垃圾短信分类数据集时的划分方式类似。下面是具体的划分比例计算方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71001363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Listing 7.3 Partitioning the dataset\n",
    "train_portion = int(len(data) * 0.85) # 85% for training\n",
    "test_portion = int(len(data) * 0.1) # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7162e3",
   "metadata": {},
   "source": [
    "在成功下载并划分数据集，同时清晰地理解了数据集的提示格式后，我们现在准备开始指令微调过程的核心实现。在接下来的部分中，我们将重点讨论如何构建用于微调 LLM 的训练批次。\n",
    "\n",
    "---\n",
    "\n",
    "## 7.3 将数据组织成训练批次\n",
    "\n",
    "随着我们进入指令微调过程的实施阶段，接下来的步骤（如图 7.5 所示）将重点介绍如何高效地构建训练批次。这一步需要定义一种方法，以确保模型在微调过程中能够接收到格式化的训练数据。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.5.png\" width=\"75%\" />\n",
    "\n",
    "在上一章中，训练批次是通过 PyTorch 的 `DataLoader` 类自动创建的，该类使用默认的`collate`函数将样本列表合并为批次。`collate` 函数的作用是将单个数据样本列表合并成一个批次，以便模型在训练过程中能够高效处理。\n",
    "\n",
    "然而，为了适应指令微调的需求，本章的批处理过程更为复杂，需要我们创建一个自定义的 collate 函数，并将其嵌入到 `DataLoader` 中，以便处理指令微调数据集的特定需求和格式。\n",
    "\n",
    "本节将分几步介绍批处理过程（包括自定义`collate`函数的编写），具体内容如图 7.6 所示。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.6.png\" width=\"75%\" />\n",
    "\n",
    "首先，为实现图 7.6 中展示的步骤 2.1 和 2.2，我们编写了一个 `InstructionDataset` 类，它应用了上一节中的 `format_input` 函数，并对数据集中的所有输入进行了预分词，类似于第 6 章中的 `SpamDataset`。这两个步骤的详细说明见图 7.7。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.7.png\" width=\"75%\" />\n",
    "\n",
    "图 7.7 中展示的 两步操作通过 `InstructionDataset` 类的 `__init__` 构造函数实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13150373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 7.4 Implementing an instruction dataset class\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:  # 预分词文本\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5127beb",
   "metadata": {},
   "source": [
    "与第 6 章的方法类似，我们通过将多个训练样本收集到一个批次中来加速训练，这需要将所有输入填充到相似的长度。对此，我们使用与前一章一样的 `<|endoftext|>` 作为填充标记。\n",
    "\n",
    "我们可以直接将 `<|endoftext|>` token 的 token ID 追加到预处理后的输入中，而不是将 `<|endoftext|>` token 本身追加到文本输入中。为了明确应该使用哪个 token ID，我们可以对 `<|endoftext|>` token 使用分词器的 `.encode` 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8a0aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68317fd1",
   "metadata": {},
   "source": [
    "在第 6 章中，我们使用的填充方式是将数据集中的所有示例填充到相同长度。在本章中，我们将采用一种更为精细的方法，开发一个自定义的`collate`函数并传递给数据加载器。该自定义`collate`函数会将每个批次中的训练样本填充到相同长度，同时允许不同批次中的样本具有不同的长度，如图 7.8 所示。这种方法通过仅将序列扩展到每个批次中最长的序列长度，从而减少了不必要的填充，避免了对整个数据集进行冗余填充。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.8.png\" width=\"75%\" />\n",
    "\n",
    "我们可以通过以下自定义`collate`函数来实现图 7.8 所示的填充过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99672959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # 找出批量中的最长序列\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst = []\n",
    "\n",
    "    # 对输入进行填充并准备好输入数据\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "\n",
    "        # 删除之前添加的多余填充 token\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)             #D\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e29e8c",
   "metadata": {},
   "source": [
    "我们实现的 `custom_collate_draft_1` 虽然设计用于集成到 PyTorch 的 DataLoader 中，但它也可以独立使用。在这里，我们单独使用它来测试和验证其功能是否符合预期。我们将在三个不同输入上进行测试，目标是将它们合并为一个批次，并对每个样本进行填充以保证长度一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8a1052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca0164",
   "metadata": {},
   "source": [
    "如输出所示，所有输入序列都已被填充到最长输入序列的长度，其中`inputs_1`包含了 5 个 token ID。\n",
    "\n",
    "我们刚刚实现了自定义 `collate` 函数的第一个版本，用于从输入列表创建批次。然而，正如在第 5 章和第 6 章中所学的那样，我们还需要创建与输入 ID 批次相对应的目标 token ID 批次。图 7.9 显示了这些目标 ID，它们非常重要，因为它们代表我们希望模型生成的内容，并且在训练时用于计算损失，从而指导模型更新权重。这与之前章节的做法类似。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.9.png\" width=\"75%\" />\n",
    "\n",
    "如图 7.9 所示，我们需要修改自定义的`collate`函数，使其在返回输入 token ID 的基础上，同时返回目标 token ID。\n",
    "\n",
    "与第 5 章中描述的 LLM 预训练过程类似，目标 token ID 与输入 token ID 一一对应，但会右移一个位置，这种设置（如图 7.10 所示）使得 LLM 能够学习如何预测序列中的下一个 token。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.10.png\" width=\"75%\" />\n",
    "\n",
    "以下为更新后的`collate`函数，它根据输入 token ID 生成目标 token ID（流程如图 7.10 所示）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a6621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])             #A\n",
    "        targets = torch.tensor(padded[1:])             #B\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)\n",
    "\n",
    "\n",
    "#A 截断输入序列的最后一个 token。\n",
    "#B 将目标序列中的每个 token 向右移动一个位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486746f3",
   "metadata": {},
   "source": [
    "对于之前定义的包含 3 个输入列表的示例批次，更新后的`custom_collate_draft_2`函数会返回输入和目标批次数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a37872",
   "metadata": {},
   "source": [
    "在接下来的步骤中，我们会将所有填充 token 设置为占位值 -100。这个特殊值可以让填充 token 不参与训练损失的计算，从而确保只有有效数据会影响模型的学习。\n",
    "\n",
    "关于这个过程的更多细节将在实施此修改后讨论。（在第 6 章中，我们无需担心这个问题，因为当时只训练了最后一个输出 token。）\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.11.png\" width=\"75%\" />\n",
    "\n",
    "如图 7.11 所示，在步骤 2.4 中，我们将文本结束 token（之前用作填充 token，token ID 为 50256）在目标 token 列表中替换为 -100（选择 -100 作为替代值的原因将在后续说明）。\n",
    "\n",
    "然而，请注意，我们在目标列表中仍保留了一个文本结束 token（ID 为 50256），如图 7.12 所示。这使得 LLM 能够学习在接收到指令时何时生成结束 token，以指示生成的响应已完成。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.12.png\" width=\"75%\" />\n",
    "\n",
    "在以下代码中，我们修改了自定义的 `collate` 函数，将目标列表中 ID 为 50256 的 token 替换为 -100，图 7.12 展示了这一操作。此外，我们引入了一个 `allowed_max_length` 参数，用于选择性地限制样本的长度。当你使用的数据集超过 GPT-2 模型支持的 1024 个 token 的上下文长度时，这一调整将非常有用。更新后的 `collate` 函数代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "657971bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 7.5 Implementing a custom batch collate function\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1]) # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:]) # Shift +1 to the right for targets\n",
    "\n",
    "        # 在 targets 中，将除第一个以外的所有填充标记替换为 ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # 可选择性地将序列截断到最大长度\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704af73b",
   "metadata": {},
   "source": [
    "我们再来尝试用最新的`custom_collate_fn`函数处理之前创建的样本批次，确认其是否按预期工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7066b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c9ab9c",
   "metadata": {},
   "source": [
    "通过打印出的结果可知，修改后的`custom_collate_fn`函数按预期工作，通过插入 token ID -100 来改变目标列表。那么，这种调整背后的逻辑是什么呢？接下来我们将深入探讨此修改的具体作用。\n",
    "\n",
    "我们可以通过一个简单、独立的示例来说明，示例中每个输出的 logit 都可以对应模型词汇表中的一个潜在 token。在训练过程中，当模型预测一系列 token 时，我们可以计算交叉熵损失（类似于我们在第 5 章中进行预训练或第 6 章中对模型进行分类微调时的做法）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6500fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0], # predictions for 1st token\n",
    "     [-0.5, 1.5]] # predictions for 2nd token\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d137c2",
   "metadata": {},
   "source": [
    "添加额外的 token ID 会影响损失计算，这是预料之中的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4f5dc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]                        #A\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)\n",
    "\n",
    "#A 添加第三个 token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6297ce6",
   "metadata": {},
   "source": [
    "添加第三个 token 后，损失值变为 0.7936。\n",
    "\n",
    "到目前为止，我们已经使用 PyTorch 中的交叉熵损失函数进行了若干较为直观的示例计算，这也是我们在第 5 章和第 6 章的训练函数中使用的损失函数，接下来我们将在本章继续使用它。\n",
    "\n",
    "现在，进入有趣的部分，看看如果我们将第三个目标 token ID 替换为 -100，会发生什么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0fba11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915d9e8",
   "metadata": {},
   "source": [
    "根据这个结果，我们可以看到，在这 3 个训练样本上的损失与之前计算的 2 个训练样本的损失相同。换句话说，交叉熵损失函数忽略了 targets_3 向量中的第三个条目，即对应 token ID 为 -100 的位置。（有兴趣的读者可以尝试将 -100 替换为其他非零、非一的 token ID，结果会导致错误。）\n",
    "\n",
    "那么，为什么 -100 会被交叉熵损失函数忽略呢？在 PyTorch 中，cross_entropy 函数的默认设置是 `cross_entropy(..., ignore_index=-100)`，这意味着它会忽略标签为 -100 的目标。\n",
    "\n",
    "在本章中，我们利用 `ignore_index` 来忽略训练示例中额外的结束token（填充token），这些 token 用于将训练样本填充至相同的长度，以便每个批次中的序列具有相同的长度。\n",
    "\n",
    "如图 7.12 所示，我们希望在目标序列中保留一个50256（结束符）token ID，因为这有助于 LLM 学习生成文本结束的标记，进而作为判断回复是否完成的标志。\n",
    "\n",
    "在实践中，除了遮蔽填充 token 外，还常常将指令部分对应的目标 token ID 一并遮蔽，如图 7.13 所示。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.13.png\" width=\"75%\" />\n",
    "\n",
    "通过对指令部分对应的目标 token ID 进行掩码（如图 7.13 所示），交叉熵损失仅计算生成响应的目标 token ID，模型在训练时也会专注于生成准确的回答，而不是去记住指令内容，从而有助于减少过拟合。\n",
    "\n",
    "目前，研究人员对于在指令微调过程中遮蔽指令是否具有普遍效果存在分歧。例如，最近有一篇题为《Instruction Tuning With Loss Over Instructions》的论文表明，不遮蔽指令有助于提升大语言模型的性能（更多细节请参考附录 B）。在本章中，我们不选择遮蔽指令，但是将其作为读者的可选练习。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **练习 7.2 指令与输入的掩码处理**\n",
    ">\n",
    "> 在完成本章内容，并用本节实现的 `InstructionDataset` 对模型进行微调后，将指令和输入 token 替换为 -100 掩码，以实现图 7.13 展示的指令掩码方法。然后，评估该方法是否对模型性能有积极影响。\n",
    "\n",
    "---\n",
    "\n",
    "## 7.4 为指令数据集创建数据加载器\n",
    "\n",
    "在前一节中，我们完成了 `InstructionDataset` 类和 `custom_collate_fn` 函数的多个实现步骤。本节中，我们可以将 `InstructionDataset` 对象和 `custom_collate_fn` 函数直接传入 PyTorch 的数据加载器中（如图 7.14 所示）。加载器将自动对批次数据进行随机化和组织，为 LLM 的指令微调过程提供支持。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.14.png\" width=\"75%\" />\n",
    "\n",
    "在我们实现图 7.14 中所示的数据加载器创建步骤之前，我们需要先简要讨论在前一节中实现的 `custom_collate_fn` 中的`device`参数设置。\n",
    "\n",
    "`custom_collate_fn` 包含将输入和目标张量（例如，torch.stack(inputs_lst).to(device)）移动到指定设备的代码，该设备可以是 \"cpu\"、\"cuda\"（GPU）或可选的 \"mps\"（适用于 Apple Silicon 芯片的 Mac）。(需要注意的是，使用 \"mps\" 设备可能会导致与本章内容存在数值差异，因为 PyTorch 对 Apple Silicon 的支持仍处于实验阶段。)\n",
    "\n",
    "在前几章中，我们习惯在主训练循环中将数据转移到目标设备上（例如，当 device=\"cuda\" 时，数据转移到 GPU 内存）。将这个数据传输步骤移入 `collate` 函数的好处在于，能够在训练循环之外的后台进程中完成数据传输，避免在模型训练时阻塞 GPU。\n",
    "\n",
    "以下代码用于初始化 device 变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "935c7f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 取消这两行注释以在 Apple Silicon 芯片上启用 GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319d25c",
   "metadata": {},
   "source": [
    "接下来，为了在稍后将 `custom_collate_fn` 函数传入 PyTorch 的 `DataLoader` 类时复用`device`参数设置，我们使用 Python 标准库 `functools` 中的 `partial` 函数，为该函数创建一个预先填充 `device` 参数的新版本。另外，我们将 `allowed_max_length` 设置为 1024，以将数据截断至 GPT-2 模型（我们将在本章后续部分进行微调）所支持的最大上下文长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c490c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14936e60",
   "metadata": {},
   "source": [
    "接着，我们可以像前几章那样设置数据加载器，但这次我们将使用自定义的 `collate` 函数来处理批次数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c10a17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 7.6 Initializing the data loaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 如果操作系统支持并行的 Python 进程，你可以尝试增加此数值。\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff503909",
   "metadata": {},
   "source": [
    "让我们检查一下由训练数据加载器生成的输入和目标批次的维度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6596ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a26ef",
   "metadata": {},
   "source": [
    "在上面的输出中，我们可以看到第一个输入和目标批次的维度是 8×61，其中 8 表示批次大小（batch size），61 表示每个样本的 token 数。第二个输入和目标批次的 token 数则不同（76 个token）。\n",
    "\n",
    "正如我们在前面的代码输出中所见，得益于自定义的`collate`函数，数据加载器可以创建包含不同长度数据的批次。在下一节，我们将加载一个预训练的 LLM ，并使用该数据加载器对模型进行微调。\n",
    "\n",
    "---\n",
    "\n",
    "## 7.5 加载预训练的 LLM\n",
    "\n",
    "在之前的部分中，我们花费了大量时间准备指令微调所需的数据集，这是监督微调过程的关键环节。除此之外，许多其他步骤也与预训练过程相同，因此我们可以复用前几章的大部分代码。\n",
    "\n",
    "在正式开始指令微调之前，我们首先需要加载一个预训练的 GPT 模型，正如图 7.15 所示，该模型是我们希望进行微调的对象。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.15.png\" width=\"75%\" />\n",
    "\n",
    "如 7.15 概述了完整的指令微调流程，本节重点介绍第 4 步，即加载预训练的 LLM ，作为指令微调的起点，过程与前几章类似。然而，这次我们加载的是 3.55 亿参数的中等模型，而非之前使用的 1.24 亿参数的小模型。选择更大模型的原因是 1.24 亿参数的小模型容量有限，难以通过指令微调获得令人满意的效果。”\n",
    "\n",
    "本节使用与第 5 章第 5.5 节和第 6 章第 6.4 节中相同的代码，不同之处在于我们这次指定了“gpt2-medium (355M)”而不是“gpt2-small (124M)”。请注意，执行下面的代码将会启动下载中等规模的 GPT 模型，该模型的存储需求约为 1.42 GB，约是小型模型所需存储空间的三倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc1c9173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "# Listing 7.7 Loading the pretrained model\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()) + '/code/')\n",
    "\n",
    "from gpt_download import download_and_load_gpt2\n",
    "from chapter4 import GPTModel\n",
    "from chapter5 import load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257, # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0, # Dropout rate\n",
    "    \"qkv_bias\": True # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d5a21b",
   "metadata": {},
   "source": [
    "在进入模型微调之前，让我们先评估一下预训练的 LLM 在某个验证集任务上的表现。具体来说，我们通过将模型的输出与预期回答进行比较，这样可以让我们在不进行微调的情况下，对模型的指令执行能力有一个基本了解，这也有助于我们理解微调的效果。我们使用验证集中的第一个例子来进行评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43ade055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c58592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chapter5 import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf27864",
   "metadata": {},
   "source": [
    "需要注意的是，`generate` 函数返回的是输入文本和输出文本的组合。这种输出方式在前几章中由于易读性被频繁使用，因为预训练的大语言模型主要设计为文本补全模型，其中输入和输出会被拼接在一起，生成连贯且易读的文本。然而，在评估模型在特定任务上的表现时，我们通常只关注模型生成的响应部分。\n",
    "\n",
    "为了提取模型的响应文本，我们需要从生成的文本起始部分减去输入指令的长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9b1ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use rendering verbs to perform a later action: 'Open the door'\n",
      "\n",
      "Notes: Make sure that either verb has an original, then-position in the verb list.\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb95f9",
   "metadata": {},
   "source": [
    "从输出结果来看，预训练模型尚未能够正确地执行给定的指令。虽然它确实创建了一个“Response”部分，但只是重复了原始输入句子和部分指令，并未如要求那样将主动语态转换为被动语态。\n",
    "\n",
    "在接下来的部分，我们将实现微调过程，以提升模型理解并恰当回应此类请求的能力。\n",
    "\n",
    "---\n",
    "\n",
    "## 7.6 指令微调 LLM\n",
    "\n",
    "图 7.16 中的章节概述展示了本节的重点：对大语言模型（LLM）进行微调。我们将在上一节加载的预训练模型基础上，利用本章前面准备的指令数据集进一步训练该模型。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.16.png\" width=\"75%\" />\n",
    "\n",
    "如前所述，我们在本章开头实现指令数据集处理时，已经完成了所有关键工作。对于微调过程本身，我们可以复用第 5 章中实现的损失计算和训练函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f04ac2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chapter5 import calc_loss_loader, train_model_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ebe703",
   "metadata": {},
   "source": [
    "在我们开始训练之前，让我们计算一下训练集和验证集的初始损失："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08bdd6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8259105682373047\n",
      "Validation loss: 3.7619349479675295\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b545957",
   "metadata": {},
   "source": [
    "初始损失值如下（与前几章一样，我们的目标是最小化这个损失）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9965159",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    ">\n",
    "> **应对硬件限制**\n",
    ">\n",
    "> 需要注意的是，使用和训练像 GPT-2 medium（355 百万个参数）这样的大型模型相比于先前章节中使用的小型 GPT-2 模型（1.24 亿参数）在计算上更加密集。如果你因硬件限制遇到问题，可以通过将 CHOOSE_MODEL = \"gpt2-medium (355M)\" 更改为 CHOOSE_MODEL = \"gpt2-small (124M)\" 来切换到较小的模型。另一种加速模型训练的方式是使用 GPU。有关使用云 GPU 的选项，请参考本书代码仓库中的补充部分：https://github.com/rasbt/LLMs-from-scratch/tree/main/setup\n",
    "\n",
    "表格 7.1 提供了在不同设备（包括 CPU 和 GPU）上训练每个模型的参考运行时间。在兼容的 GPU 上运行此代码无需修改代码，并且能够显著加快训练速度。对于本章展示的结果，我使用了 GPT-2 中型模型，并在 A100 GPU 上进行了训练。\n",
    "\n",
    "<img src=\"../Image/chapter7/table_7.1.png\" width=\"75%\" />\n",
    "\n",
    "模型和数据加载器准备好后，我们可以开始训练模型。以下代码设置了训练过程的各项配置，包括初始化优化器、设置训练轮次、定义评估频率，并基于之前提到的第一个验证集样本（val_data[0]）来评估训练过程中生成的 LLM 响应："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80d0948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.800, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.809\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.535, Val loss 0.732\n",
      "Ep 1 (Step 000075): Train loss 0.567, Val loss 0.736\n",
      "Ep 1 (Step 000080): Train loss 0.602, Val loss 0.731\n",
      "Ep 1 (Step 000085): Train loss 0.513, Val loss 0.715\n",
      "Ep 1 (Step 000090): Train loss 0.571, Val loss 0.696\n",
      "Ep 1 (Step 000095): Train loss 0.504, Val loss 0.687\n",
      "Ep 1 (Step 000100): Train loss 0.507, Val loss 0.682\n",
      "Ep 1 (Step 000105): Train loss 0.568, Val loss 0.674\n",
      "Ep 1 (Step 000110): Train loss 0.562, Val loss 0.669\n",
      "Ep 1 (Step 000115): Train loss 0.519, Val loss 0.665\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.437, Val loss 0.670\n",
      "Ep 2 (Step 000125): Train loss 0.454, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.681\n",
      "Ep 2 (Step 000135): Train loss 0.406, Val loss 0.677\n",
      "Ep 2 (Step 000140): Train loss 0.407, Val loss 0.676\n",
      "Ep 2 (Step 000145): Train loss 0.373, Val loss 0.677\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.674\n",
      "Ep 2 (Step 000155): Train loss 0.419, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.414, Val loss 0.686\n",
      "Ep 2 (Step 000165): Train loss 0.380, Val loss 0.688\n",
      "Ep 2 (Step 000170): Train loss 0.327, Val loss 0.679\n",
      "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.668\n",
      "Ep 2 (Step 000180): Train loss 0.390, Val loss 0.657\n",
      "Ep 2 (Step 000185): Train loss 0.417, Val loss 0.659\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.650\n",
      "Ep 2 (Step 000195): Train loss 0.326, Val loss 0.636\n",
      "Ep 2 (Step 000200): Train loss 0.311, Val loss 0.632\n",
      "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.628\n",
      "Ep 2 (Step 000210): Train loss 0.367, Val loss 0.628\n",
      "Ep 2 (Step 000215): Train loss 0.393, Val loss 0.635\n",
      "Ep 2 (Step 000220): Train loss 0.300, Val loss 0.647\n",
      "Ep 2 (Step 000225): Train loss 0.346, Val loss 0.662\n",
      "Ep 2 (Step 000230): Train loss 0.299, Val loss 0.657\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked everyday by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 6.12 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Listing 7.8 Instruction finetuning the pretrained LLM\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d64970",
   "metadata": {},
   "source": [
    "以下输出显示了经过两个训练周期的进展，稳步下降的损失值表明模型在理解指令和生成合适回答方面的能力正在提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec550d98",
   "metadata": {},
   "source": [
    "训练输出表明模型正在有效学习，我们可以通过训练和验证损失值在两个周期中的持续下降看出这一点。这表明模型正在逐渐提高其理解和执行提供的指令的能力。 （由于模型在这两个周期内展示了有效的学习，延长训练周期到第三个周期或更多并非必要，反而可能适得其反，因为这可能导致过拟合。）\n",
    "\n",
    "此外，每一轮训练结束时生成的响应可以帮助我们检查模型在验证集示例上正确执行任务的进展。在这个例子中，模型成功地将主动语态句子‘The chef cooks the meal every day.’ 转换为被动语态‘The meal is cooked every day by the chef.’\n",
    "\n",
    "我们将在后续部分更详细地回顾并评估模型的响应质量。现在，为了总结本节内容，我们将分析训练和验证损失曲线，从中获得有关模型学习过程的更多见解。为此，我们使用第 5 章中的 `plot_losses` 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ed2aaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()  # 创建与 y 轴共用的第二个 x 轴\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 用于对齐刻度的隐藏图形\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a39dde",
   "metadata": {},
   "source": [
    "由此生成的损失曲线如图 7.17 所示。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.17.png\" width=\"75%\" />\n",
    "\n",
    "如图 7.17 的损失图所示，模型在训练集和验证集上的表现随着训练的进行显著提高。在初期阶段，损失的快速下降表明模型正在迅速学习数据中的有意义的模式和表示。随着训练进入第二个 epoch，损失继续减少，但速度放缓，表明模型正在微调其学习到的表示，并逐渐收敛到一个稳定的解。\n",
    "\n",
    "尽管图 7.17 中的损失曲线表明模型正在有效训练，但最关键的方面是其在响应质量和正确性上的表现。在本章接下来的部分，我们将提取响应，并将其存储为一种便于评估和量化响应质量的格式。\n",
    "\n",
    "> **练习 7.3 在原始 Alpaca 数据集上进行微调**\n",
    ">\n",
    "> 斯坦福大学研究人员创建的 Alpaca 数据集是最早且最受欢迎的公开共享指令数据集之一，包含了 52,002 条数据。作为本章中使用的`instruction-data.json`文件的替代，可以考虑在这个数据集上对 LLM 进行微调。该数据集可通过以下网址获取：https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json。\n",
    ">\n",
    "> 该数据集包含 52,002 条记录，约为本章使用数据集的 50 倍，且大部分记录的长度也较长。因此，强烈建议使用 GPU 来加速微调过程。如果遇到内存不足错误，可以考虑将批量大小（batch_size）从 8 降至 4、2，甚至 1。此外，降低最大长度（allowed_max_length）从 1024 调整为 512 或 256，也有助于缓解内存问题。\n",
    "\n",
    "---\n",
    "\n",
    "## 7.7 提取并保存响应\n",
    "\n",
    "在之前内容中，我们已经对 LLM 在指令数据集的训练部分进行微调，现在我们开始评估其在测试集上的表现。为此，我们首先对测试集中的每个输入生成模型的回答，并收集这些结果以便人工分析，详见图 7.18。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.18.png\" width=\"75%\" />\n",
    "\n",
    "我们从步骤 7 开始（详见图 7.18），通过`generate`函数输出模型回答，并将其与预期的前三个测试集答案并排展示，便于进行对比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ece8963f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is a thunderstorm that causes extensive surface and regional winds, typically from 20 to 30 miles per hour (40 to 50 kilometers per hour).\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' was George Bernard Shaw.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "# 遍历测试集中的前三个样本\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    # 使用在第 7.5 节导入的 generate 函数\n",
    "    token_ids = generate(                  #B\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\",\n",
    "\"\").strip()\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4efee",
   "metadata": {},
   "source": [
    "如前所述，`generate`函数会返回合并后的输入和输出文本，因此我们可以对 `generated_text` 内容使用切片和 `.replace()` 方法，提取出模型的回复。以下展示了指令、测试集中的预期回复以及模型的实际回复："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3139a6",
   "metadata": {},
   "source": [
    "从测试集的指令、给定的参考回答以及模型生成的回答来看，模型整体表现相对较好。第一个和最后一个指令的回答明显正确，而第二个回答虽然接近正确，但并非完全准确。模型将‘积云’回答成了‘积雨云’。需要注意的是，积云可以发展成积雨云，而积雨云有可能产生雷暴。\n",
    "\n",
    "最重要的是，我们可以看到，模型评估并不像上一章那样简单，在上一章中，我们只是通过计算正确的垃圾短信/非垃圾短信标签的百分比来获得分类准确率。而在实际应用中，像聊天机器人这样的指令微调大语言模型（instruction-finetuned LLMs）则需要通过多种方法进行评估：\n",
    "\n",
    "+ 简答题和多项选择题的基准测试（如 MMLU，\"评估大规模多任务语言理解能力\"，论文地址：https://arxiv.org/abs/2009.03300），用于测试模型的通用知识水平。\n",
    "+ 基于人类偏好对其他大语言模型进行比较，例如 LMSYS 的 Chatbot Arena 平台（https://arena.lmsys.org）。\n",
    "+ 自动化对话基准测试，使用像 GPT-4 这样的 LLM 来评估回答，例如 AlpacaEval（https://tatsulab.github.io/alpaca_eval/）。\n",
    "\n",
    "在实践中，以上三种评估方法（多项选择题回答、人工评估和自动化指标）都可以选择。然而，我们在本章主要关注对话性能的评估，而不仅仅是回答多选题的能力，因此第二种（人工评估）和第三种（自动化指标）可能更为相关。\n",
    "\n",
    "人工评估虽然能够提供宝贵的见解，但在处理大量回复时往往耗时费力。例如，阅读并为 1,100 条回复逐一评分将需要投入相当大的精力。\n",
    "\n",
    "考虑到任务规模，我们将采用类似‘方法3’的方案，通过另一个大语言模型（LLM）对生成的响应进行自动评估。这种方法能够高效地评估响应质量，无需大量的人力参与，从而节省时间和资源，同时仍能获得有意义的性能指标。\n",
    "\n",
    "在接下来的部分中，我们将借鉴 AlpacaEval 的评估方法，使用另一个 LLM 来评估微调模型的响应。然而，与依赖公开的基准测试数据集不同，我们使用了自定义测试集。这样可以更有针对性地评估模型在实际应用场景中的表现，以反映微调所用指令数据集中所代表的目标任务效果。\n",
    "\n",
    "为了准备评估过程中需要的响应，我们将生成的模型响应追加到 `test_set` 字典中，并将更新后的数据保存为名为 `instructiondata-with-response.json` 的文件以便记录。此外，保存这个文件后，我们可以在将来的 Python 会话中轻松加载和分析这些响应数据。\n",
    "\n",
    "以下代码与之前一样使用了 `generate` 方法，但这次模型的响应不再直接打印，而是被添加到 `test_set` 字典中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec699ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:35<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Listing 7.9 Generating test set responses\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\",\n",
    "\"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"../data/instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4) # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ef2cd",
   "metadata": {},
   "source": [
    "在 A100 GPU 上处理此数据集大约需要 1 分钟，而在 M3 MacBook Air 上则需要约 6 分钟。\n",
    "\n",
    "我们来验证一下响应是否已正确添加到测试集字典中，可以通过检查其中一个条目来实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "124260e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f8a73f",
   "metadata": {},
   "source": [
    "最后，我们将模型保存为文件 gpt2-medium355M-sft.pth，以便在未来的项目中复用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad8a544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Remove white spaces and parentheses from file name\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a7c2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7.8 评估指令微调后的 LLM\n",
    "\n",
    "之前章节中，我们通过查看模型在测试集中的 3 个示例上的响应来评估指令微调模型的性能。虽然这种方法可以提供模型表现的大致概况，但不适合用于大规模响应的评估。因此，我们在本节中实现了一种新方法（如图 7.19 的章节概览所示），利用另一个更大的大语言模型对微调模型的响应进行自动化评估。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.19.png\" width=\"75%\" />\n",
    "\n",
    "为了实现图 7.19 中第 9 步（以自动化方式评估测试集响应），我们使用了 Meta AI 开发的一个经过指令微调的 Llama 3 模型，该模型拥有 80 亿参数，可以通过开源应用程序 Ollama 在本地运行（官网：[https://ollama.com](https://ollama.com)）。\n",
    "\n",
    "Ollama 是一个高效的应用程序，适用于在笔记本电脑上运行大语言模型（LLM）。它是开源库 `llama.cpp`（[https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)）的封装，该库用纯 C/C++ 实现了 LLM，旨在最大化效率。然而，需要注意的是，Ollama 仅用于使用 LLM 生成文本（推理），并不支持训练或微调 LLM。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **通过Web API使用更强大的 LLM**\n",
    ">\n",
    "> 拥有 80 亿参数的 Llama 3 模型是一款性能非常强大的 LLM，能够在本地运行。然而，与 OpenAI 提供的 GPT-4 等商业化大模型相比，Llama 3 的能力稍显不足。如果读者感兴趣，可以通过 OpenAI 的 API 使用 GPT-4 来评估生成的模型响应。相关代码笔记本已作为本书的补充材料提供，读者可访问以下 GitHub 链接获取更多信息：\n",
    "> https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/03_model-evaluation/llm-instruction-eval-openai.ipynb\n",
    "\n",
    "为运行以下代码，请访问 https://ollama.com 并根据您的操作系统说明安装 Ollama：\n",
    "\n",
    "+ 针对 macOS 和 Windows 用户：打开已下载的 Ollama 应用。如果提示安装命令行工具，请选择‘是’。\n",
    "+ 针对 Linux 用户：请使用 Ollama 网站提供的安装命令。\n",
    "\n",
    "在实现模型评估代码之前，我们需要先下载 Llama 3 模型，并通过命令行验证 Ollama 是否正常运行。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.20.png\" width=\"75%\" />\n",
    "\n",
    "如图 7.20 所示，在另一终端中运行 Ollama 应用程序或 Ollama 服务后，请在命令行（不是在 Python 会话中）执行以下命令来运行具有 80 亿参数的 Llama 3 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama run llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499dc99",
   "metadata": {},
   "source": [
    "首次执行该命令时， Llama 3 模型（占用 4.7 GB 存储空间）将会自动下载。下载后的输出如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec83848",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulling manifest\n",
    "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB\n",
    "pulling 4fa551d4f938... 100% ▕████████████████▏ 12 KB\n",
    "pulling 8ab4849b038c... 100% ▕████████████████▏ 254 B\n",
    "pulling 577073ffcc6c... 100% ▕████████████████▏ 110 B\n",
    "pulling 3f8eb4da87fa... 100% ▕████████████████▏ 485 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "removing any unused layers\n",
    "success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b74a65",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    ">\n",
    "> **Ollama 模型的替代方案**\n",
    ">\n",
    "> 需要注意的是，`ollama run llama3` 命令中的 `llama3` 指的是一个经过指令微调的 Llama 3 模型，具有 80 亿参数。运行 `llama3` 模型时，大约需要 16 GB 的内存。如果设备内存不足，建议尝试更小的模型，例如参数量为 38 亿的 `phi-3` 模型，该模型通过 `ollama run llama3` 命令加载，仅需约 8 GB 内存即可运行。\n",
    ">\n",
    "> 对于高性能计算机，你可以选择更大的 Llama 3 模型（700 亿参数版本），只需将 `llama3` 替换为 `llama3:70b`。但请注意，该模型对计算资源的需求会显著增加。\n",
    "\n",
    "当模型下载完成后，系统会显示一个命令行界面，用来与模型进行交互。例如，你可以试着向模型提问：“What do llamas eat?“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "259b22c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2070251980.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Llamas are ruminant animals, which means they have a four-chambered\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ">>> What do llamas eat?\n",
    "Llamas are ruminant animals, which means they have a four-chambered\n",
    "stomach and eat plants that are high in fiber. In the wild, llamas\n",
    "typically feed on:\n",
    "1. Grasses: They love to graze on various types of grasses, including tall\n",
    "grasses, wheat, oats, and barley."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa09fb05",
   "metadata": {},
   "source": [
    "需要注意的是，Ollama 模型在当前版本中具有非确定性，因此你看到的响应可能会有所不同。\n",
    "\n",
    "你可以通过输入 `/bye` 来结束当前的 ollama run llama3 会话。但请确保在本章剩余内容中，后台的 ollama serve 命令或 Ollama 应用程序继续保持运行。\n",
    "\n",
    "以下代码用于验证 Ollama 会话是否正常运行，以便在评估上一节生成的测试集响应之前确保其可用性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daef485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a16be",
   "metadata": {},
   "source": [
    "请确保执行以上代码的输出结果为 “Ollama running: True”。如果显示为 False，请检查是否已正确运行 `ollama serve` 命令或 Ollama 应用程序。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **在一个新的 Python 会话中运行代码**\n",
    ">\n",
    "> 如果你在第 7.7 节后关闭了 Python 会话，或者希望在新的会话中运行本章后续代码，可以执行以下代码。这些代码将加载我们在第 7.7 节中创建的指令和响应数据文件，同时重新定义之前使用的 `format_input` 函数（后续代码中还会使用 `tqdm` 进度条工具）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e921bb",
   "metadata": {},
   "source": [
    "一种替代 `ollama run` 命令与模型交互的方法是通过 Python 使用其 REST API。以下 `query_model` 函数示例演示了如何使用该 API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4809cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 7.10 Querying a local Ollama model\n",
    "import urllib.request\n",
    "\n",
    "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/chat\"):\n",
    "    data = {                                                               #A\n",
    "        \"model\": model,\n",
    "        \"seed\": 123, # for deterministic responses\n",
    "        \"temperature\": 0, # for deterministic responses\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    payload = json.dumps(data).encode(\"utf-8\")                             #B\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\")     #C\n",
    "    request.add_header(\"Content-Type\", \"application/json\")                 #C\n",
    "\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:                      #D\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    return response_data\n",
    "\n",
    "\n",
    "#A 将数据载荷创建为字典格式\n",
    "#B 将字典转换为 JSON 格式字符串，并编码为字节数据\n",
    "#C 创建请求对象，设置方法为 POST，并添加必要的请求头\n",
    "#D 发送请求并接收响应"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abb159",
   "metadata": {},
   "source": [
    "考虑到每个学习者的使用电脑配置不同，这里使用 DeepSeek 的 API 来查询模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e48fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"xxxxxxx\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "def query_model(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a5ebc",
   "metadata": {},
   "source": [
    "在执行后续代码之前，请确保 Ollama 服务仍在运行。之前的代码应输出‘Ollama running: True’，以确保模型已启动并可以接收请求。\n",
    "\n",
    "接下来，我们通过以下示例说明如何使用刚实现的 `query_llama` 函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c52d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores and primarily eat grasses, hay, and other plant materials. Their diet typically includes:\n",
      "\n",
      "1. **Grass and Hay** – The bulk of their diet consists of fresh grass or high-quality hay (such as timothy, alfalfa, or orchard grass).  \n",
      "2. **Grains and Pellets** – In moderation, they can eat fortified llama or alpaca pellets for extra nutrients.  \n",
      "3. **Vegetables and Fruits** – Occasionally, they enjoy treats like carrots, apples, or leafy greens (but avoid excessive sugar).  \n",
      "4. **Mineral Supplements** – Llamas need access to salt licks or mineral blocks to maintain proper nutrient levels.  \n",
      "\n",
      "They have efficient digestive systems (similar to cows and sheep) and chew cud to break down tough plant fibers. Avoid overfeeding grains or sugary foods, as this can cause digestive issues.  \n",
      "\n",
      "If you're caring for llamas, ensure they have clean water, good-quality forage, and a balanced diet tailored to their age and activity level.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6796dec",
   "metadata": {},
   "source": [
    "了解了 `query_model` 函数的用法，我们现在可以通过一个`prompt`来评估微调模型的响应质量。具体来说，`prompt`要求 Llama 3 模型根据测试集中的参考响应，对微调模型的响应进行 0 到 100 的评分。\n",
    "\n",
    "首先，我们将这种方法用于测试集的前三个样本，这些样本已在前文中分析过："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5362f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "\n",
      "Score:\n",
      ">> The model response \"The car is as fast as a cheetah.\" is a well-constructed simile that effectively conveys the speed of the car. \n",
      "\n",
      "Here's the scoring breakdown:\n",
      "- **Accuracy**: The simile is accurate and makes logical sense (cheetahs are known for their speed). (30/30)\n",
      "- **Creativity**: While cheetahs are a common metaphor for speed, the response is still creative and appropriate. (25/25)\n",
      "- **Clarity**: The sentence is clear and easy to understand. (25/25)\n",
      "- **Relevance**: The simile is highly relevant to the original sentence. (20/20)\n",
      "\n",
      "**Total Score: 100/100**  \n",
      "\n",
      "The response is excellent and fully meets the criteria for a good simile. While \"lightning\" is also a great simile, \"cheetah\" is equally valid and vivid.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is amorphous clouds.\n",
      "\n",
      "Score:\n",
      ">> The correct answer is \"cumulonimbus,\" which is the cloud type specifically known for producing thunderstorms. The model's response, \"amorphous clouds,\" is incorrect because \"amorphous\" is not a recognized cloud type associated with thunderstorms. \n",
      "\n",
      "Here’s the scoring breakdown:\n",
      "- **Accuracy**: 0 (completely incorrect cloud type)\n",
      "- **Relevance**: 10 (the response is about clouds but entirely wrong)\n",
      "- **Clarity**: 50 (the sentence is grammatically clear but factually wrong)\n",
      "\n",
      "**Overall Score: 20/100**  \n",
      "\n",
      "The low score reflects the significant factual inaccuracy, despite the response being grammatically coherent.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> The model response `The author of 'Pride and Prejudice' is Jane Austen.` is highly accurate and complete, providing the correct author and the title of the book in a grammatically correct sentence. \n",
      "\n",
      "Here's the scoring breakdown:\n",
      "- **Accuracy**: 100 (The response correctly identifies Jane Austen as the author.)\n",
      "- **Completeness**: 100 (The response fully answers the question without missing any details.)\n",
      "- **Clarity**: 100 (The response is clear and easy to understand.)\n",
      "- **Grammar/Syntax**: 100 (The sentence is grammatically correct.)\n",
      "\n",
      "Overall, the response is excellent and meets all the criteria perfectly. \n",
      "\n",
      "**Final Score: 100**\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660de49c",
   "metadata": {},
   "source": [
    "这将打印出类似于以下的输出（请注意，截至本文写作时，Ollama 不是完全确定性的，因此生成的文本可能会有所不同）："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969fdb9",
   "metadata": {},
   "source": [
    "通过生成的回答可以看出，Llama 3 模型具有合理的评估能力，即使答案不完全正确，也能够给予部分分数。例如，在对“cumulus cloud”这一回答的评估中，模型能够识别答案中的部分正确性，并对此作出相应评价。\n",
    "\n",
    "以上的`promp返回的不仅有评分，还包括高度详细的评价内容。我们可以修改`prompt`，使其只生成 0 到 100 的整数评分（其中 100 表示最高分）。这样一来，我们就可以计算模型的平均分，将其作为对模型性能更简洁且量化的评估。\n",
    "\n",
    "下面的 `generate_model_scores` 函数使用了一个修改后的`prompt`，要求模型‘仅回复整数’："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ab4c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 7.11 Evaluating the instruction finetuning LLM\n",
    "def generate_model_scores(json_data, json_key):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"  # 修改后的指令设置为仅返回分数\n",
    "        )\n",
    "        score = query_model(prompt)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dad731fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [07:40<00:00,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 39.91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's now apply the generate_model_scores function to the entire test_data set, which takes about 1 minute on a M3 Macbook Air:\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206cdde1",
   "metadata": {},
   "source": [
    "评估结果显示，我们的微调模型平均得分为 40 分，这为与其他模型进行对比提供了一个有用的基准，同时也可以基于该基准尝试不同的训练配置，以进一步提升模型的性能。\n",
    "\n",
    "需要注意的是，撰写本文时，Ollama 的结果并非完全固定，这意味着您得到的分数可能会与上述结果略有不同。为了获得更稳定的结果，可以重复多次评估，并取平均值。\n",
    "\n",
    "为了提升模型性能，我们可探索多种策略，例如：\n",
    "\n",
    "+\t在微调阶段，可以通过调整超参数（如学习率、批次大小和训练轮数）来优化模型性能。\n",
    "+\t通过扩大训练数据集规模或丰富样本的多样性，以覆盖更广泛的主题和风格。\n",
    "+\t尝试不同的提示或指令格式，以更有效地引导模型的回答。\n",
    "+\t考虑使用更大的预训练模型，这类模型可能具有更强的能力，能够捕捉复杂模式并生成更准确的响应。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **LLaMA 3 模型性能**\n",
    ">\n",
    "> 作为参考，使用本节描述的方法，Llama 3 8B 基础模型（未经过任何微调）在测试集上的平均得分为 58.51。而经过在通用指令遵循数据集上微调的 Llama 3 8B 指令模型，在测试集上的平均得分高达 82.6，表现相当出色。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **练习 7.4：使用 LoRA 实现参数高效微调**\n",
    ">\n",
    "> 为了更高效地对 LLM 进行指令微调，请修改本章的代码，采用附录 E 中的 LoRA 方法。然后，对比修改前后训练时长和模型性能。\n",
    "\n",
    "---\n",
    "\n",
    "## 7.9 结语\n",
    "\n",
    "本章总结了大语言模型（LLM）开发流程的关键步骤，包括实现 LLM 架构、预训练模型以及针对特定任务的微调，具体内容可参考图 7.21。\n",
    "\n",
    "<img src=\"../Image/chapter7/figure7.21.png\" width=\"75%\" />\n",
    "\n",
    "接下来的小节将为你提供一些思路，帮助你在完成图 7.21 中展示的关键步骤后，进一步探索下去。\n",
    "\n",
    "\n",
    "\n",
    "### 7.9.1 接下来如何做？\n",
    "\n",
    "尽管我们已经讲解了模型训练的核心步骤（详见图 7.21），但在完成指令微调后，还可以选择进行偏好微调（Preference Finetuning）。偏好微调对于定制模型以更好地符合特定用户的需求尤为有用。如果您希望进一步了解这一过程，可以参考书籍补充资源中的 GitHub 仓库（[链接](https://github.com/rasbt/LLMs-from-scratch/tree/main/ch07/04_preference-tuning-withdpo)），查看 `04_preference-tuning-with-dpo` 文件夹。\n",
    "\n",
    "除了书中涵盖的主要内容外，GitHub 仓库还提供了丰富的额外材料，这些内容可能对您非常有价值。如需了解更多，请访问仓库 README 页面的“Bonus Material”部分：https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material。\n",
    "\n",
    "\n",
    "\n",
    "### 7.9.2 如何在快速变化的前沿领域中保持领先\n",
    "\n",
    "人工智能和大语言模型的研究领域正在迅速发展（许多人可能觉得这非常令人兴奋）。想要了解最新进展，可以浏览 arXiv 上的最新研究论文（网址：[https://arxiv.org/list/cs.LG/recent](https://arxiv.org/list/cs.LG/recent)）。此外，许多研究人员和从业者也会在社交媒体平台（如 X（原 Twitter）和 Reddit）上积极分享和讨论最新动态。尤其是 Reddit 的 r/LocalLLaMA 版块，是了解社区动态以及最新工具和趋势的好资源。\n",
    "\n",
    "我会定期在博客上分享关于大语言模型（LLM）研究的最新动态和见解，您可以通过以下地址访问：https://magazine.sebastianraschka.com 和 https://sebastianraschka.com/blog/。\n",
    "\n",
    "感谢你一路同行，祝愿你在未来的大语言模型和人工智能领域的探索中一切顺利！\n",
    "\n",
    "---\n",
    "\n",
    "## 7.10 本章摘要\n",
    "\n",
    "+ 指令微调的过程旨在将预训练的大语言模型调整为能够遵循人类指令并生成预期回答。\n",
    "+ 准备数据集需要下载指令-响应数据集，对数据进行格式化，并划分为训练集、验证集和测试集。\n",
    "+ 自定义的`collate`函数用于构建训练批次，处理过程包括对序列数据进行填充，生成目标 token 的 ID，并对填充的 token 进行掩码处理。\n",
    "+ 我们加载了一个具有 3.55 亿参数的预训练 GPT-2 medium 模型，作为指令微调的起点。\n",
    "+ 预训练模型在指令数据集上进行了微调，训练方式类似于预训练的循环。\n",
    "+ 评估涉及在测试集上提取模型响应并对其进行评分，例如，使用另一个LLM进行评分。\n",
    "+ Ollama 应用利用一个 80 亿参数的 Llama 模型，可以对微调模型在测试集上的响应进行自动评分，并通过平均分来量化模型的性能表现。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
