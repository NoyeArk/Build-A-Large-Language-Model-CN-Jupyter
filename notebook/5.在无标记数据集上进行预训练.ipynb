{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046f4d98",
   "metadata": {},
   "source": [
    "# 5. 在无标记数据集上进行预训练\n",
    "\n",
    "本章涵盖以下内容：\n",
    "\n",
    "+ **计算训练集和验证集的损失，以评估训练过程中大型语言模型生成文本的质量**\n",
    "+ **实现训练函数并预训练大语言模型**\n",
    "+ **保存和加载模型权重以便继续训练大语言模型**\n",
    "+ **从OpenAI加载预训练权重**\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "- [5.1 生成式文本模型的评估](#51-生成式文本模型的评估)\n",
    "  - [5.1.1 使用 GPT 生成文本](#511-使用-gpt-生成文本)\n",
    "  - [5.1.2 文本生成损失的计算](#512-文本生成损失的计算)\n",
    "  - [5.1.3 计算训练集和验证集的损失](#513-计算训练集和验证集的损失)\n",
    "- [5.2 训练 LLM](#52-训练-llm)\n",
    "- [5.3 通过解码策略控制生成结果的随机性](#53-通过解码策略控制生成结果的随机性)\n",
    "  - [5.3.1 Temperature scaling](#531-temperature-scaling)\n",
    "  - [5.3.2 Top-k 采样](#532-top-k-采样)\n",
    "  - [5.3.3 对文本生成函数进行调整](#533-对文本生成函数进行调整)\n",
    "- [5.4 在 PyTorch 中加载和保存模型权重](#54-在-pytorch-中加载和保存模型权重)\n",
    "- [5.5 从 OpenAI 加载预训练权重](#55-从-openai-加载预训练权重)\n",
    "- [5.6 本章摘要](#56-本章摘要)\n",
    "\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "\n",
    "在之前的章节中，我们实现了数据采样、注意力机制，并编写了 LLM 的架构。本章的核心是实现训练函数并对 LLM 进行预训练，详见图 5.1。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.1.png\" width=\"75%\" />\n",
    "\n",
    "如图5.1所示，我们将继续学习基本的模型评估技术，以衡量生成文本的质量，这对于在训练过程中优化 LLM 是非常必要的。此外，我们将讨论如何加载预训练权重，以便为接下来的微调提供坚实的基础。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **权重参数**\n",
    ">\n",
    "> 在大语言模型（LLM）和其他深度学习模型中，权重指的是可以通过训练过程调整的参数，通常也被称为权重参数或直接称为参数。在 PyTorch 等框架中，这些权重通常存储在各层（如线性层）中，举例来说，我们在第 3 章实现的多头注意力模块和第 4 章实现的GPT模型中就使用了线性层。在初始化一个层（例如，`new_layer = torch.nn.Linear(...)`）后，我们可以通过`.weight`属性访问其权重，例如`new_layer.weight`。此外，出于便利性，PyTorch还允许通过`model.parameters()`方法直接访问模型的所有可训练参数，包括权重和偏置，我们将在后续实现模型训练时使用该方法。\n",
    "\n",
    "\n",
    "\n",
    "## 5.1 生成式文本模型的评估\n",
    "\n",
    "本章开篇，我们将基于上一章的代码设置 LLM 进行文本生成，并讨论如何对生成文本质量进行评估的基本方法。而本章剩余部分的内容请参考图5.2。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.2.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.2 所示，接下来的小节我们首先简要回顾上一章末尾的文本生成过程，然后深入探讨文本评估及训练和验证损失的计算方法。\n",
    "\n",
    "\n",
    "\n",
    "### 5.1.1 使用 GPT 生成文本\n",
    "\n",
    "在本节中，我们会先通过对 LLM 的设置简要回顾一下第四章中实现的文本生成过程。在开始这项工作之前，我们首先使用第 4 章中的 GPTModel 类和 GPT_CONFIG_124M 配置字典初始化 GPT 模型，以便在后续章节对其进行评估和训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbb5566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()) + '/code/')\n",
    "\n",
    "import torch\n",
    "from chapter4 import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,  # 我们将上下文长度从1024个token缩短到256个token\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,       # 将 dropout 设置为 0 是一种常见的做法\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661f055",
   "metadata": {},
   "source": [
    "在之前定义的 GPT_CONFIG_124M 配置字典中，我们唯一的调整是将上下文长度（context_length）减少到 256 个 token。此项调整降低了模型训练的计算需求，使得可以在普通笔记本电脑上进行训练。\n",
    "\n",
    "参数量为 1.24 亿的 GPT-2 模型最初被配置为可处理最多 1024 个 token。本章结束时，我们将更新上下文大小设置，并加载预训练权重，使模型能够支持 1024-token 的上下文长度。\n",
    "\n",
    "我们通过前一章节中介绍的 generate_text_simple 函数来使用 GPTmodel 实例，同时引入了两个实用函数：text_to_token_ids 和token_ids_to_text。这些函数简化了文本与 token 表示之间的转换，本章中我们将多次使用这种技术。图 5.3 可以帮助我们更清楚地理解这一过程。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.3.png\" width=\"75%\" />\n",
    "\n",
    "图 5.3 展示了使用 GPT 模型生成文本的三个主要步骤。首先，分词器将输入文本转换为一系列 token ID（在第 2 章中已有讨论）。然后，模型接收这些 token ID 并生成对应的 logits（即词汇表中每个 token 的概率分布，具体见第 4 章）。最后，将 logits 转换回 token ID，分词器将其解码为可读的文本，完成从文本输入到文本输出的循环。\n",
    "\n",
    "我们通过代码来实现上述过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccfd47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "# Listing 5.1 Utility functions for text to token ID conversion\n",
    "import tiktoken\n",
    "from chapter4 import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d221d0d",
   "metadata": {},
   "source": [
    "从输出可以看出，模型尚未生成连贯的文本，因为它还没有经过训练。为了定义文本的‘连贯性’或‘高质量’，我们需要实现一种数值方法来评估生成的内容。这一方法将帮助我们在训练过程中监督并提升模型的性能。\n",
    "\n",
    "接下来将介绍如何计算生成内容的损失度量，该损失值会作为训练进展和效果的指示器。此外，在后续关于微调 LLM 的章节中，我们将探讨更多评估模型质量的方法。\n",
    "\n",
    "\n",
    "\n",
    "### 5.1.2 文本生成损失的计算\n",
    "\n",
    "本节将探讨如何通过计算‘文本生成损失’来数值化评估训练过程中生成的文本质量。在通过一个实际示例逐步讲解这一主题之前，先简要回顾第 2 章的数据加载方式以及第 4 章的`generate_text_simple`函数如何生成文本。\n",
    "\n",
    "图 5.4 展示了从输入文本到 LLM 生成文本的整体流程，该流程通过五个步骤实现。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.4.png\" width=\"75%\" />\n",
    "\n",
    "图 5.4 展示了第 4 章中`generate_text_simple`函数内部的本生成过程。在后续章节中计算生成文本的质量损失之前，我们需要先执行这些初始步骤。\n",
    "\n",
    "为了便于在一页中展示图像，我们图中的示例仅使用了包含 7 个 token 的小型词汇表。然而，GPTModel 实际上使用了包含 50,257 个 token 的大型词汇表，因此在接下来的代码中，token ID 的范围为 0 到 50,256，而不是图示中的 0 到 6。\n",
    "\n",
    "此外，图 5.4 为了简洁仅展示了一个文本示例 'every effort moves'。在接下来的代码示例中，我们将实现图 5.4 中的步骤，并使用两个输入示例 'every effort moves' 和 'I really like' 作为 GPT 模型的输入。\n",
    "\n",
    "考虑两个输入样本，它们已经被转换为 token ID，对应图 5.4 中的步骤 1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac6901ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                       [40, 1107, 588]])    # \"I really like\"]\n",
    "# Matching these inputs, the `targets` contain the token IDs we aim for the model to produce:\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                        [107, 588, 11311]]) # \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293ba3b",
   "metadata": {},
   "source": [
    "需要注意的是，目标值中展示的是输入数据向前偏移了一个位置。我们在第 2 章实现数据加载器时已介绍过这一概念。这种偏移策略对于教会模型预测序列中的下一个 token 至关重要。\n",
    "\n",
    "接着我们将两个输入示例（每个示例样本包含三个 token）输入模型以计算它们的 logit 向量，再应用 Softmax 函数将这些 logit 值转换为概率得分，这对应于图 5.4 中的步骤 2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7f6817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# 禁用梯度跟踪，因为我们尚未进行训练\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4788223",
   "metadata": {},
   "source": [
    "第一个数字 2 表示输入中的两个样本（行），即批次大小。第二个数字 3 表示每个样本包含的 token 数量。最后一个数字表示嵌入维度的大小，通常由词汇表大小决定，前面章节已讨论。\n",
    "\n",
    "通过 softmax 函数将 logits 转换为概率后，第 4 章的 generate_text_simple 函数会将概率得分进一步转换回文本，这一过程在图 5.4 的步骤 3 到步骤 5 中进行了展示。\n",
    "\n",
    "接下来，通过对概率得分应用 `argmax` 函数，可以得到对应的 token ID（实现步骤 3 和 步骤 4）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57123174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802896f4",
   "metadata": {},
   "source": [
    "假设我们有 2 个输入样本，每个样本包含 3 个 token。在对概率得分应用 argmax 函数后（对应图 5.4 的第 3 步），会得到 2 组输出，每组包含 3 个预测的 token ID。\n",
    "\n",
    "最后，步骤 5 将 token ID 转换回文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22369123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b5e09",
   "metadata": {},
   "source": [
    "可以看到，模型生成的文本与目标文本不同，因为它尚未经过训练。接下来，我们将通过‘损失’来数值化评估模型生成文本的质量（详见图 5.5）。这不仅有助于衡量生成文本的质量，还为实现训练函数提供了基础，训练函数主要通过更新模型权重来改善生成文本的质量。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.5.png\" width=\"75%\" />\n",
    "\n",
    "文本评估过程的一部分（如图 5.5 所示）是衡量生成的 token 与正确预测目标之间的差距。本章后面实现的训练函数将利用这些信息来调整模型权重，使生成的文本更接近（或理想情况下完全匹配）目标文本。\n",
    "\n",
    "换句话说，模型训练的目标是提高正确目标 token ID 所在位置的 softmax 概率，如图 5.6 所示。接下来的部分中，我们还会将该 softmax 概率作为评价指标，用于对模型生成的输出进行数值化评估：正确位置上的概率越高，模型效果越好。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.6.png\" width=\"75%\" />\n",
    "\n",
    "请注意，图 5.6 使用了一个包含 7 个 token 的简化词汇表，以便所有内容可以在一张图中展示。这意味着 softmax 的初始随机值会在 1/7 左右（约 0.14）。\n",
    "\n",
    "然而，我们为 GPT-2 模型使用的词汇表包含 50,257 个 token，因此每个 token 的初始概率大约只有 0.00002（即 1/50,257）。\n",
    "\n",
    "对于这两个输入文本，我们可以通过以下代码打印与目标 token 对应的初始 softmax 概率得分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19dfb143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([3.9108e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b517ccc",
   "metadata": {},
   "source": [
    "训练 LLM 的目标就是最大化这些概率值，使其尽量接近 1。这样可以确保 LLM 始终选择目标 token —— 即句中的下一个词，作为生成的下一个 token。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **反向传播**\n",
    ">\n",
    "> 如何最大化目标 token 的 softmax 概率值？整体思路是通过更新模型权重，使模型在生成目标 token 时输出更高的概率值。权重更新通过一种称为反向传播的过程来实现，这是一种训练深度神经网络的标准技术（关于反向传播和模型训练的更多细节可见附录 A 的 A.3 至 A.7 节）。\n",
    ">\n",
    "> 反向传播需要一个损失函数，该函数用于计算模型预测输出与实际目标输出之间的差异（此处指与目标 token ID 对应的概率）。这个损失函数用于衡量模型预测与目标值的偏差程度。\n",
    "\n",
    "在本节剩余内容中，我们将针对`target_probas_1`和`target_probas_2`的概率得分计算损失。图 5.7 展示了主要步骤。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.7.png\" width=\"75%\" />\n",
    "\n",
    "由于我们已经完成了图 5.7 中列出的步骤 1-3，得到了 `target_probas_1` 和 `target_probas_2`，现在进行第 4 步，对这些概率得分取对数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc1671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -10.1492,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97883d9",
   "metadata": {},
   "source": [
    "在数学优化中，处理概率得分的对数比直接处理概率得分更为简便。该主题超出本书的讨论范围，但我在一个讲座中对此进行了详细讲解，链接位于附录 B 的参考部分。\n",
    "\n",
    "> [!TIP]\n",
    ">\n",
    "> **个人思考：** 在继续接下来的计算之前，我们首先来探讨一下，对数在损失函数的应用中到底有什么作用。\n",
    ">\n",
    "> 1. **为什么要用概率的对数**\n",
    ">\n",
    ">    在 LLM 中，概率得分通常是小于1的数（例如0.1、0.05等），直接用这些数进行计算和优化可能会面临一些问题。比如，如果多个概率相乘，结果会变得非常小，甚至接近0。这种情况称为“数值下溢”（Numerical Underflow），可能导致计算不稳定。\n",
    ">\n",
    ">    假设我们有三个概率值，分别为0.2、0.1和0.05。如果我们计算这些值的乘积，结果是：\n",
    ">\n",
    ">    $$0.2×0.1×0.05=0.001$$\n",
    ">\n",
    ">    这个值非常小，尤其在深度学习或概率模型中，我们通常会有成千上万个概率需要相乘，这样会导致最终的乘积接近0甚至为0，造成数值计算的不稳定性。\n",
    ">\n",
    ">    如果我们对这些概率值取对数，然后相加，而不是直接相乘，我们可以避免这个问题。例如，对这三个值取自然对数（logarithm）后再相加：\n",
    ">\n",
    ">    $$ln(0.2)+ln(0.1)+ln(0.05)≈−1.6094+(−2.3026)+(−2.9957)=−6.9077$$\n",
    ">\n",
    ">    虽然这个和也是负数，但它不会像直接相乘的结果那样接近于0，避免了数值下溢的问题。**对数的累加性质**允许我们将原本的累乘操作转换为累加，使得计算更加稳定和高效。\n",
    ">\n",
    ">\n",
    "> 2. **对数概率在损失函数中的作用**\n",
    ">\n",
    ">    GPT模型训练的目标是最大化正确目标 token 的概率，通常，我们会使用交叉熵损失来衡量模型预测与实际目标之间的差异。对于一个目标 token 序列 $y=(y1,y2,…,yn)$，GPT会生成一个对应的预测概率分布 $P(y|x)$，其中 $x$ 是模型的输入。\n",
    ">\n",
    ">    **交叉熵损失的公式：**\n",
    ">\n",
    ">    在计算交叉熵损失时，我们希望最大化模型分配给每个正确目标token的概率。交叉熵损失的数学公式为：\n",
    ">\n",
    ">    $$\\text { Loss }=-\\sum_{t=1}^{T} \\ln P\\left(y_{t} \\mid x, \\theta\\right)$$\n",
    ">\n",
    ">    其中：\n",
    ">\n",
    ">    + $T$ 是序列长度\n",
    ">    + $y_{t}$ 是在位置 $t$ 上的目标 token\n",
    ">    + $P(y_{t}|x,\\theta)$ 是模型在参数 $\\theta$ 下对目标 token $y_{t}$ 的条件概率\n",
    ">\n",
    ">    在公式中，对每个 token 的概率 $P(y_{t}|x,\\theta)$ 取对数，将乘积形式的联合概率转换为求和形式，有助于避免数值下溢，同时简化优化过程。\n",
    "\n",
    "接下来，通过计算平均值将这些对数概率合并为一个评分（参见图 5.7 的第 5 步）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7573f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.5722)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201468f",
   "metadata": {},
   "source": [
    "训练的目标就是通过更新模型权重，使平均对数概率尽可能接近 0（将在 5.2 节中实现）。\n",
    "\n",
    "然而，在深度学习中，常见做法并不是直接将平均对数概率推向 0，而是通过将负平均对数概率降低至 0 来实现。负平均对数概率就是平均对数概率乘以 -1，这与图 5.7 的第 6 步相对应："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a52c3dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5722)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af6027e",
   "metadata": {},
   "source": [
    "结算的结果为：`tensor(10.5722)`。\n",
    "\n",
    "这种将负值 -10.5722 转化为正值 10.5722 的操作在深度学习中称为交叉熵损失。\n",
    "\n",
    "在这里，PyTorch 非常实用，因为它内置的 cross_entropy 函数已经自动处理了图 5.7 中的 6 个步骤。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **交叉熵损失**\n",
    ">\n",
    "> 本质上，交叉熵损失是在机器学习和深度学习中一种常用的度量方法，用于衡量两个概率分布之间的差异——通常是标签的真实分布（此处为数据集中的 token）和模型的预测分布（例如，LLM 生成的 token 概率）。\n",
    ">\n",
    "> 在机器学习，特别是 PyTorch 等框架中，cross_entropy 函数用于计算离散输出的损失，与模型生成的 token 概率下的目标 token 的负平均对数概率类似。因此，cross entropy 和负平均对数概率这两个术语在计算上有关联，实践中经常互换使用。\n",
    "\n",
    "在应用交叉熵函数之前，我们先简要回顾一下 logits 和目标张量的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61500716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c71f5a",
   "metadata": {},
   "source": [
    "可以看到，logits 是个三维张量（批量大小、token 数量和词汇表大小）。而 targets 是个二维张量（批量大小和 token 数量）。\n",
    "\n",
    "在 PyTorch 中使用交叉熵损失函数时，我们需要将这些张量展平，以便在批量维度上进行合并："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13c1c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d765f",
   "metadata": {},
   "source": [
    "请记住，targets 是希望 LLM 生成的目标 token ID，而 logits 包含了在进入 softmax 函数之前的模型原始输出。\n",
    "\n",
    "我们之前的实现是先应用 Softmax 函数，再选择目标 token ID 对应的概率分数，计算负的平均对数概率。而在 PyTorch 中，`cross_entropy` 函数能够自动完成所有这些步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0629e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5722)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e19e1f",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    ">\n",
    "> **Perplexity**\n",
    ">\n",
    "> `Perplexity` 是一种经常与交叉熵损失一起使用的指标，用于评估语言建模等任务中的模型表现。它能够以更具可解释性的方式，帮助理解模型在预测下一个 token 时的不确定性。\n",
    ">\n",
    "> `Perplexity` 常用于衡量模型预测的概率分布与数据集中词的实际分布的接近程度。类似于损失函数，`Perplexity`的值越低，表示模型预测越接近真实分布。\n",
    ">\n",
    "> `Perplexity`可通过 `perplexity = torch.exp(loss)` 计算，对先前计算的损失值应用此公式将返回 `tensor(48725.8203)`。\n",
    ">\n",
    "> `Perplexity`通常比原始损失值更具可解释性，因为它表示了模型在每一步生成中，对有效词汇量的不确定程度。在这个例子中，`Perplexity`可以理解为模型在词汇表中的 47,678 个单词或 token 中，不确定该选择哪个作为下一个生成的 token。\n",
    "\n",
    "在本节中，我们对两个小文本输入进行了损失计算，以便更直观地说明损失函数的计算过程。下一节将把损失计算应用于整个训练集和验证集。\n",
    "\n",
    "\n",
    "\n",
    "### 5.1.3 计算训练集和验证集的损失\n",
    "\n",
    "在本节中，我们首先准备训练和验证数据集，以用于后续 LLM 的训练。接着，我们计算训练集和验证集的交叉熵（如图 5.8 所示），这是模型训练过程中的重要组成部分。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.8.png\" width=\"75%\" />\n",
    "\n",
    "为了计算训练集和验证集上的损失（如图 5.8 所示），我们使用了一个非常小的文本数据集，即伊迪丝·华顿的短篇小说《判决》，我们在第 2 章中已对此文本进行过处理。选择公共领域的文本可以避免任何关于使用权的担忧。此外，我们选择小数据集的原因在于，它允许代码示例在普通笔记本电脑上运行，即使没有高端 GPU 也能在几分钟内完成，这对于教学尤为有利。\n",
    "\n",
    "感兴趣的读者可以使用本书的配套代码，准备一个包含超过 60,000 本 Project Gutenberg 公有领域书籍的大规模数据集，并在此数据集上训练 LLM（详情请见附录 D）。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **预训练 LLM 的成本**\n",
    ">\n",
    "> 为了更好地理解项目的规模，以一个相对受欢迎的开源 LLM - 70 亿参数的 Llama 2 模型的训练为例。该模型的训练在昂贵的 A100 GPU 上共耗费了 184,320 个小时，处理了 2 万亿个 token。在撰写本文时，AWS 上 8 张 A100 卡的云服务器每小时费用约为 30 美元。粗略估算，训练这样一个 LLM 的总成本约为 69 万美元（计算方法为 184,320 小时除以 8，再乘以 30 美元）。\n",
    "\n",
    "以下代码用于加载我们在第 2 章中使用的《判决》短篇小说："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6343939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\\n\\n\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it\\'s going to send the value of my picture \\'way up; but I don\\'t think of that, Mr. Rickham--the loss to Arrt is all I think of.\" The word, on Mrs. Thwing\\'s lips, multiplied its _rs_ as though they were reflected in an endless vista of mirrors. And it was not only the Mrs. Thwings who mourned. Had not the exquisite Hermia Croft, at the last Grafton Gallery show, stopped me before Gisburn\\'s \"Moon-dancers\" to say, with tears in her eyes: \"We shall not look upon its like again\"?\\n\\nWell!--even through the prism of Hermia\\'s tears I felt able to face the fact with equanimity. Poor Jack Gisburn! The women had made him--it was fitting that they should mourn him. Among his own sex fewer regrets were heard, and in his own trade hardly a murmur. Professional jealousy? Perhaps. If it were, the honour of the craft was vindicated by little Claude Nutley, who, in all good faith, brought out in the Burlington a very handsome \"obituary\" on Jack--one of those showy articles stocked with random technicalities that I have heard (I won\\'t say by whom) compared to Gisburn\\'s painting. And so--his resolve being apparently irrevocable--the discussion gradually died out, and, as Mrs. Thwing had predicted, the price of \"Gisburns\" went up.\\n\\nIt was not till three years later that, in the course of a few weeks\\' idling on the Riviera, it suddenly occurred to me to wonder why Gisburn had given up his painting. On reflection, it really was a tempting problem. To accuse his wife would have been too easy--his fair sitters had been denied the solace of saying that Mrs. Gisburn had \"dragged him down.\" For Mrs. Gisburn--as such--had not existed till nearly a year after Jack\\'s resolve had been taken. It might be that he had married her--since he liked his ease--because he didn\\'t want to go on painting; but it would have been hard to prove that he had given up his painting because he had married her.\\n\\nOf course, if she had not dragged him down, she had equally, as Miss Croft contended, failed to \"lift him up\"--she had not led him back to the easel. To put the brush into his hand again--what a vocation for a wife! But Mrs. Gisburn appeared to have disdained it--and I felt it might be interesting to find out why.\\n\\nThe desultory life of the Riviera lends itself to such purely academic speculations; and having, on my way to Monte Carlo, caught a glimpse of Jack\\'s balustraded terraces between the pines, I had myself borne thither the next day.\\n\\nI found the couple at tea beneath their palm-trees; and Mrs. Gisburn\\'s welcome was so genial that, in the ensuing weeks, I claimed it frequently. It was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fullest reassurance. It was just because she was _not_ interesting--if I may be pardoned the bull--that I found her so. For Jack, all his life, had been surrounded by interesting women: they had fostered his art, it had been reared in the hot-house of their adulation. And it was therefore instructive to note what effect the \"deadening atmosphere of mediocrity\" (I quote Miss Croft) was having on him.\\n\\nI have mentioned that Mrs. Gisburn was rich; and it was immediately perceptible that her husband was extracting from this circumstance a delicate but substantial satisfaction. It is, as a rule, the people who scorn money who get most out of it; and Jack\\'s elegant disdain of his wife\\'s big balance enabled him, with an appearance of perfect good-breeding, to transmute it into objects of art and luxury. To the latter, I must add, he remained relatively indifferent; but he was buying Renaissance bronzes and eighteenth-century pictures with a discrimination that bespoke the amplest resources.\\n\\n\"Money\\'s only excuse is to put beauty into circulation,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gisburn, beaming on him, added for my enlightenment: \"Jack is so morbidly sensitive to every form of beauty.\"\\n\\nPoor Jack! It had always been his fate to have women say such things of him: the fact should be set down in extenuation. What struck me now was that, for the first time, he resented the tone. I had seen him, so often, basking under similar tributes--was it the conjugal note that robbed them of their savour? No--for, oddly enough, it became apparent that he was fond of Mrs. Gisburn--fond enough not to see her absurdity. It was his own absurdity he seemed to be wincing under--his own attitude as an object for garlands and incense.\\n\\n\"My dear, since I\\'ve chucked painting people don\\'t say that stuff about me--they say it about Victor Grindle,\" was his only protest, as he rose from the table and strolled out onto the sunlit terrace.\\n\\nI glanced after him, struck by his last word. Victor Grindle was, in fact, becoming the man of the moment--as Jack himself, one might put it, had been the man of the hour. The younger artist was said to have formed himself at my friend\\'s feet, and I wondered if a tinge of jealousy underlay the latter\\'s mysterious abdication. But no--for it was not till after that event that the _rose Dubarry_ drawing-rooms had begun to display their \"Grindles.\"\\n\\nI turned to Mrs. Gisburn, who had lingered to give a lump of sugar to her spaniel in the dining-room.\\n\\n\"Why _has_ he chucked painting?\" I asked abruptly.\\n\\nShe raised her eyebrows with a hint of good-humoured surprise.\\n\\n\"Oh, he doesn\\'t _have_ to now, you know; and I want him to enjoy himself,\" she said quite simply.\\n\\nI looked about the spacious white-panelled room, with its _famille-verte_ vases repeating the tones of the pale damask curtains, and its eighteenth-century pastels in delicate faded frames.\\n\\n\"Has he chucked his pictures too? I haven\\'t seen a single one in the house.\"\\n\\nA slight shade of constraint crossed Mrs. Gisburn\\'s open countenance. \"It\\'s his ridiculous modesty, you know. He says they\\'re not fit to have about; he\\'s sent them all away except one--my portrait--and that I have to keep upstairs.\"\\n\\nHis ridiculous modesty--Jack\\'s modesty about his pictures? My curiosity was growing like the bean-stalk. I said persuasively to my hostess: \"I must really see your portrait, you know.\"\\n\\nShe glanced out almost timorously at the terrace where her husband, lounging in a hooded chair, had lit a cigar and drawn the Russian deerhound\\'s head between his knees.\\n\\n\"Well, come while he\\'s not looking,\" she said, with a laugh that tried to hide her nervousness; and I followed her between the marble Emperors of the hall, and up the wide stairs with terra-cotta nymphs poised among flowers at each landing.\\n\\nIn the dimmest corner of her boudoir, amid a profusion of delicate and distinguished objects, hung one of the familiar oval canvases, in the inevitable garlanded frame. The mere outline of the frame called up all Gisburn\\'s past!\\n\\nMrs. Gisburn drew back the window-curtains, moved aside a _jardiniere_ full of pink azaleas, pushed an arm-chair away, and said: \"If you stand here you can just manage to see it. I had it over the mantel-piece, but he wouldn\\'t let it stay.\"\\n\\nYes--I could just manage to see it--the first portrait of Jack\\'s I had ever had to strain my eyes over! Usually they had the place of honour--say the central panel in a pale yellow or _rose Dubarry_ drawing-room, or a monumental easel placed so that it took the light through curtains of old Venetian point. The more modest place became the picture better; yet, as my eyes grew accustomed to the half-light, all the characteristic qualities came out--all the hesitations disguised as audacities, the tricks of prestidigitation by which, with such consummate skill, he managed to divert attention from the real business of the picture to some pretty irrelevance of detail. Mrs. Gisburn, presenting a neutral surface to work on--forming, as it were, so inevitably the background of her own picture--had lent herself in an unusual degree to the display of this false virtuosity. The picture was one of Jack\\'s \"strongest,\" as his admirers would have put it--it represented, on his part, a swelling of muscles, a congesting of veins, a balancing, straddling and straining, that reminded one of the circus-clown\\'s ironic efforts to lift a feather. It met, in short, at every point the demand of lovely woman to be painted \"strongly\" because she was tired of being painted \"sweetly\"--and yet not to lose an atom of the sweetness.\\n\\n\"It\\'s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride. \"The last but one,\" she corrected herself--\"but the other doesn\\'t count, because he destroyed it.\"\\n\\n\"Destroyed it?\" I was about to follow up this clue when I heard a footstep and saw Jack himself on the threshold.\\n\\nAs he stood there, his hands in the pockets of his velveteen coat, the thin brown waves of hair pushed back from his white forehead, his lean sunburnt cheeks furrowed by a smile that lifted the tips of a self-confident moustache, I felt to what a degree he had the same quality as his pictures--the quality of looking cleverer than he was.\\n\\nHis wife glanced at him deprecatingly, but his eyes travelled past her to the portrait.\\n\\n\"Mr. Rickham wanted to see it,\" she began, as if excusing herself. He shrugged his shoulders, still smiling.\\n\\n\"Oh, Rickham found me out long ago,\" he said lightly; then, passing his arm through mine: \"Come and see the rest of the house.\"\\n\\nHe showed it to me with a kind of naive suburban pride: the bath-rooms, the speaking-tubes, the dress-closets, the trouser-presses--all the complex simplifications of the millionaire\\'s domestic economy. And whenever my wonder paid the expected tribute he said, throwing out his chest a little: \"Yes, I really don\\'t see how people manage to live without that.\"\\n\\nWell--it was just the end one might have foreseen for him. Only he was, through it all and in spite of it all--as he had been through, and in spite of, his pictures--so handsome, so charming, so disarming, that one longed to cry out: \"Be dissatisfied with your leisure!\" as once one had longed to say: \"Be dissatisfied with your work!\"\\n\\nBut, with the cry on my lips, my diagnosis suffered an unexpected check.\\n\\n\"This is my own lair,\" he said, leading me into a dark plain room at the end of the florid vista. It was square and brown and leathery: no \"effects\"; no bric-a-brac, none of the air of posing for reproduction in a picture weekly--above all, no least sign of ever having been used as a studio.\\n\\nThe fact brought home to me the absolute finality of Jack\\'s break with his old life.\\n\\n\"Don\\'t you ever dabble with paint any more?\" I asked, still looking about for a trace of such activity.\\n\\n\"Never,\" he said briefly.\\n\\n\"Or water-colour--or etching?\"\\n\\nHis confident eyes grew dim, and his cheeks paled a little under their handsome sunburn.\\n\\n\"Never think of it, my dear fellow--any more than if I\\'d never touched a brush.\"\\n\\nAnd his tone told me in a flash that he never thought of anything else.\\n\\nI moved away, instinctively embarrassed by my unexpected discovery; and as I turned, my eye fell on a small picture above the mantel-piece--the only object breaking the plain oak panelling of the room.\\n\\n\"Oh, by Jove!\" I said.\\n\\nIt was a sketch of a donkey--an old tired donkey, standing in the rain under a wall.\\n\\n\"By Jove--a Stroud!\" I cried.\\n\\nHe was silent; but I felt him close behind me, breathing a little quickly.\\n\\n\"What a wonder! Made with a dozen lines--but on everlasting foundations. You lucky chap, where did you get it?\"\\n\\nHe answered slowly: \"Mrs. Stroud gave it to me.\"\\n\\n\"Ah--I didn\\'t know you even knew the Strouds. He was such an inflexible hermit.\"\\n\\n\"I didn\\'t--till after. . . . She sent for me to paint him when he was dead.\"\\n\\n\"When he was dead? You?\"\\n\\nI must have let a little too much amazement escape through my surprise, for he answered with a deprecating laugh: \"Yes--she\\'s an awful simpleton, you know, Mrs. Stroud. Her only idea was to have him done by a fashionable painter--ah, poor Stroud! She thought it the surest way of proclaiming his greatness--of forcing it on a purblind public. And at the moment I was _the_ fashionable painter.\"\\n\\n\"Ah, poor Stroud--as you say. Was _that_ his history?\"\\n\\n\"That was his history. She believed in him, gloried in him--or thought she did. But she couldn\\'t bear not to have all the drawing-rooms with her. She couldn\\'t bear the fact that, on varnishing days, one could always get near enough to see his pictures. Poor woman! She\\'s just a fragment groping for other fragments. Stroud is the only whole I ever knew.\"\\n\\n\"You ever knew? But you just said--\"\\n\\nGisburn had a curious smile in his eyes.\\n\\n\"Oh, I knew him, and he knew me--only it happened after he was dead.\"\\n\\nI dropped my voice instinctively. \"When she sent for you?\"\\n\\n\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\\n\\nHe laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I couldn\\'t look at that thing--couldn\\'t face it. But I forced myself to put it here; and now it\\'s cured me--cured me. That\\'s the reason why I don\\'t dabble any more, my dear Rickham; or rather Stroud himself is the reason.\"\\n\\nFor the first time my idle curiosity about my companion turned into a serious desire to understand him better.\\n\\n\"I wish you\\'d tell me how it happened,\" I said.\\n\\nHe stood looking up at the sketch, and twirling between his fingers a cigarette he had forgotten to light. Suddenly he turned toward me.\\n\\n\"I\\'d rather like to tell you--because I\\'ve always suspected you of loathing my work.\"\\n\\nI made a deprecating gesture, which he negatived with a good-humoured shrug.\\n\\n\"Oh, I didn\\'t care a straw when I believed in myself--and now it\\'s an added tie between us!\"\\n\\nHe laughed slightly, without bitterness, and pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"\\n\\nHe placed them at my elbow and continued to wander up and down the room, stopping now and then beneath the picture.\\n\\n\"How it happened? I can tell you in five minutes--and it didn\\'t take much longer to happen. . . . I can remember now how surprised and pleased I was when I got Mrs. Stroud\\'s note. Of course, deep down, I had always _felt_ there was no one like him--only I had gone with the stream, echoed the usual platitudes about him, till I half got to think he was a failure, one of the kind that are left behind. By Jove, and he _was_ left behind--because he had come to stay! The rest of us had to let ourselves be swept along or go under, but he was high above the current--on everlasting foundations, as you say.\\n\\n\"Well, I went off to the house in my most egregious mood--rather moved, Lord forgive me, at the pathos of poor Stroud\\'s career of failure being crowned by the glory of my painting him! Of course I meant to do the picture for nothing--I told Mrs. Stroud so when she began to stammer something about her poverty. I remember getting off a prodigious phrase about the honour being _mine_--oh, I was princely, my dear Rickham! I was posing to myself like one of my own sitters.\\n\\n\"Then I was taken up and left alone with him. I had sent all my traps in advance, and I had only to set up the easel and get to work. He had been dead only twenty-four hours, and he died suddenly, of heart disease, so that there had been no preliminary work of destruction--his face was clear and untouched. I had met him once or twice, years before, and thought him insignificant and dingy. Now I saw that he was superb.\\n\\n\"I was glad at first, with a merely aesthetic satisfaction: glad to have my hand on such a \\'subject.\\' Then his strange life-likeness began to affect me queerly--as I blocked the head in I felt as if he were watching me do it. The sensation was followed by the thought: if he _were_ watching me, what would he say to my way of working? My strokes began to go a little wild--I felt nervous and uncertain.\\n\\n\"Once, when I looked up, I seemed to see a smile behind his close grayish beard--as if he had the secret, and were amusing himself by holding it back from me. That exasperated me still more. The secret? Why, I had a secret worth twenty of his! I dashed at the canvas furiously, and tried some of my bravura tricks. But they failed me, they crumbled. I saw that he wasn\\'t watching the showy bits--I couldn\\'t distract his attention; he just kept his eyes on the hard passages between. Those were the ones I had always shirked, or covered up with some lying paint. And how he saw through my lies!\\n\\n\"I looked up again, and caught sight of that sketch of the donkey hanging on the wall near his bed. His wife told me afterward it was the last thing he had done--just a note taken with a shaking hand, when he was down in Devonshire recovering from a previous heart attack. Just a note! But it tells his whole history. There are years of patient scornful persistence in every line. A man who had swum with the current could never have learned that mighty up-stream stroke. . . .\\n\\n\"I turned back to my work, and went on groping and muddling; then I looked at the donkey again. I saw that, when Stroud laid in the first stroke, he knew just what the end would be. He had possessed his subject, absorbed it, recreated it. When had I done that with any of my things? They hadn\\'t been born of me--I had just adopted them. . . .\\n\\n\"Hang it, Rickham, with that face watching me I couldn\\'t do another stroke. The plain truth was, I didn\\'t know where to put it--_I had never known_. Only, with my sitters and my public, a showy splash of colour covered up the fact--I just threw paint into their faces. . . . Well, paint was the one medium those dead eyes could see through--see straight to the tottering foundations underneath. Don\\'t you know how, in talking a foreign language, even fluently, one says half the time not what one wants to but what one can? Well--that was the way I painted; and as he lay there and watched me, the thing they called my \\'technique\\' collapsed like a house of cards. He didn\\'t sneer, you understand, poor Stroud--he just lay there quietly watching, and on his lips, through the gray beard, I seemed to hear the question: \\'Are you sure you know where you\\'re coming out?\\'\\n\\n\"If I could have painted that face, with that question on it, I should have done a great thing. The next greatest thing was to see that I couldn\\'t--and that grace was given me. But, oh, at that minute, Rickham, was there anything on earth I wouldn\\'t have given to have Stroud alive before me, and to hear him say: \\'It\\'s not too late--I\\'ll show you how\\'?\\n\\n\"It _was_ too late--it would have been, even if he\\'d been alive. I packed up my traps, and went down and told Mrs. Stroud. Of course I didn\\'t tell her _that_--it would have been Greek to her. I simply said I couldn\\'t paint him, that I was too moved. She rather liked the idea--she\\'s so romantic! It was that that made her give me the donkey. But she was terribly upset at not getting the portrait--she did so want him \\'done\\' by some one showy! At first I was afraid she wouldn\\'t let me off--and at my wits\\' end I suggested Grindle. Yes, it was I who started Grindle: I told Mrs. Stroud he was the \\'coming\\' man, and she told somebody else, and so it got to be true. . . . And he painted Stroud without wincing; and she hung the picture among her husband\\'s things. . . .\"\\n\\nHe flung himself down in the arm-chair near mine, laid back his head, and clasping his arms beneath it, looked up at the picture above the chimney-piece.\\n\\n\"I like to fancy that Stroud himself would have given it to me, if he\\'d been able to say what he thought that day.\"\\n\\nAnd, in answer to a question I put half-mechanically--\"Begin again?\" he flashed out. \"When the one thing that brings me anywhere near him is that I knew enough to leave off?\"\\n\\nHe stood up and laid his hand on my shoulder with a laugh. \"Only the irony of it is that I _am_ still painting--since Grindle\\'s doing it for me! The Strouds stand alone, and happen once--but there\\'s no exterminating our kind of art.\"\\n\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../data/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57f04a",
   "metadata": {},
   "source": [
    "加载数据集后，我们可以查看其中的字符数和 token 数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25de6625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20482\n",
      "Tokens: 5147\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869cea00",
   "metadata": {},
   "source": [
    "仅有 5,147 个 token，看起来似乎不足以训练一个 LLM，但正如前面提到的，这仅用于教学演示，因此我们可以将代码的运行时间控制在几分钟，而不是几周。此外，在本章最后，我们将把 OpenAI 的预训练权重加载到我们的 GPTModel 代码中。\n",
    "\n",
    "接下来，我们将数据集划分为训练集和验证集，并使用第二章的数据加载器为 LLM 训练准备需输入的批量数据。图 5.9 展示了该过程。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.9.png\" width=\"75%\" />\n",
    "\n",
    "出于可视化的需要，图 5.9 将最大长度设置为 6。然而，在实际数据加载器中，我们会将最大长度设置为 LLM 支持的 256 个 token 的上下文长度，使得模型在训练时可以看到更长的文本。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **处理变长输入的训练**\n",
    ">\n",
    "> 在训练模型时，我们可以使用大小相似的数据块来保证训练过程的简便和高效。然而，在实践中，使用变长的输入进行训练往往有助于提升 LLM 的泛化能力，使其在应用时能够适应不同类型的输入。\n",
    "\n",
    "为了实现图 5.9 中的数据划分与加载，我们首先定义一个 `train_ratio`，用于将 90% 的数据用于训练，剩余 10% 用于在训练期间进行模型评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a23060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506f20ff",
   "metadata": {},
   "source": [
    "现在可以使用 train_data 和 val_data 子集，复用第 2 章中的 create_dataloader_v1 代码来创建相应的数据加载器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68281e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chapter2 import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74abce",
   "metadata": {},
   "source": [
    "在前面的代码示例中，由于数据集较小，我们使用了较小的批量以降低计算资源的消耗。实际训练 LLM 时，批量大小达到 1,024 或更高并不少见。\n",
    "\n",
    "为了确认数据加载器是否正确创建，可以通过遍历这些数据加载器来检查："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32c894aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021251b",
   "metadata": {},
   "source": [
    "可以看到，训练集中共有 9 个批次，每批包含 2 个样本，每个样本有 256 个 token。由于只分配了 10% 的数据用于验证，因此验证集中只有 1 个批次，包含 2 个样本。\n",
    "\n",
    "> 这里解释一下为什么训练集一共有 9 个批次，首先计算训练集的token数量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a3b316b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4612"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321dcbc",
   "metadata": {},
   "source": [
    "> 一共有 4612 个 token，然后每个训练数据的 token 长度为 256，同时 batch_size 为 2，所以一共有 4612 / 256 / 2 = 9.0078125，向下取整为 9。\n",
    "\n",
    "> 验证集同理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488afc63",
   "metadata": {},
   "source": [
    "和我们的预期一致，输入数据（$x$）和目标数据（$y$）的形状相同（即批次大小 × 每批的 token 数量），因为目标数据是将输入数据整体向后偏移一个位置得到的，正如第 2 章讨论的那样。\n",
    "\n",
    "接下来我们实现一个工具函数，用于计算由训练和验证加载器返回的批量数据的交叉熵损失："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0704136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    # 将数据传输到指定设备（如 GPU），使数据能够在 GPU 上处理\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d0ffc",
   "metadata": {},
   "source": [
    "现在我们可以使用 `calc_loss_batch` 工具函数来实现 `calc_loss_loader` 函数，`calc_loss_loader` 将用于计算指定数据加载器中的指定数据批次的损失:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4701cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.2 Function to compute the training and validation loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:  # 如果没有指定批次数，将自动遍历所有批次\n",
    "        num_batches = len(data_loader)\n",
    "    else:  # 若批次数超过数据加载器的总批次数，则减少批次数使其与数据加载器的批次数相匹配\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()  # 每个批次的损失求和\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches  # 对所有批次的损失取平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff2316",
   "metadata": {},
   "source": [
    "默认情况下，`calc_loss_batch` 函数会遍历 `data loader` 中的所有批次数据，将每批次的损失累加到 `total_loss` 中，并计算所有批次的平均损失。作为替代方案，我们可以通过 `num_batches` 参数指定更少的批次数，以加快模型训练过程中的评估速度。\n",
    "\n",
    "现在让我们看看如何将 `calc_loss_batch` 函数应用到训练集和验证集加载器中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39e38557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583690219456\n",
      "Validation loss: 11.021605491638184\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e9df5",
   "metadata": {},
   "source": [
    "模型未经过训练，因此损失值较高。相比之下，如果模型学会按训练集和验证集中的真实顺序生成下一个 token，损失值就会接近 0。\n",
    "\n",
    "现在我们已经有了评估生成文本质量的方法，接下来我们将训练 LLM 以减少损失，从而提升文本生成的效果，如图 5.10 所示。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.10.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.10 所示，下一节将重点讲解 LLM 的预训练过程。在模型训练完成后，将应用不同的文本生成策略，并保存和加载预训练模型的权重。\n",
    "\n",
    "---\n",
    "\n",
    "## 5.2 训练 LLM\n",
    "\n",
    "在本节中，我们将实现 LLM（基于GPTModel）的预训练代码。我们重点采用一种简单的训练循环方式来保证代码简洁易读（如图 5.11 所示）。不过，有兴趣的读者可以在附录 D 中了解更多高级技术，包括学习率预热、余弦退火和梯度裁剪等，以进一步完善训练循环。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.11.png\" width=\"75%\" />\n",
    "\n",
    "图 5.11 中的流程图展示了一个典型的 PyTorch 神经网络训练流程，我们用它来训练大语言模型（LLM）。流程概述了 8 个步骤，从迭代各个 epoch 开始，处理批次数据、重置和计算梯度、更新权重，最后进行监控步骤如打印损失和生成文本样本。如果你对使用 PyTorch 如何训练深度神经网络不太熟悉，可以参考附录 A 中的 A.5 至 A.8 节。\n",
    "\n",
    "我们可以通过以下`train_model_simple`函数来实现这一训练流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "534f6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.3 The main function for pretraining LLMs\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37bafd",
   "metadata": {},
   "source": [
    "注意，我们刚刚创建的 `train_model_simple` 函数使用了两个尚未定义的函数：`evaluate_model` 和 `generate_and_print_sample`。\n",
    "\n",
    "`evaluate_model` 函数对应图 5.11 中的步骤 7。该函数会在每次模型更新后打印训练集和验证集的损失，从而帮助我们评估训练是否改进了模型。\n",
    "\n",
    "更具体地说，`evaluate_model` 函数会在训练集和验证集上计算损失，同时确保模型处于评估模式，并在计算损失时禁用梯度跟踪和 dropout："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa1c6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774e374",
   "metadata": {},
   "source": [
    "与 `evaluate_model` 类似，`generate_and_print_sample` 是一个工具函数，用于跟踪模型在训练过程中是否有改进。具体来说，`generate_and_print_sample` 函数接收一个文本片段（`start_context`）作为输入，将其转换为 token ID，并传递给 LLM，借助之前的 `generate_text_simple` 函数生成文本示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72b62694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \")) # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4546ed",
   "metadata": {},
   "source": [
    "`evaluate_model`函数通过数值来评估模型的训练进展，而`generate_and_print_sample text`函数则通过生成的实际文本示例，帮助我们在训练过程中判断模型的能力。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **ADAMW**\n",
    ">\n",
    "> Adam 优化器在深度神经网络训练中非常流行。然而在我们的训练循环中，我们选择了 AdamW 优化器。AdamW 是 Adam 的一种变体，通过改进权重衰减方式，帮助减少模型复杂度，并通过惩罚较大的权重来防止过拟合。这样的调整使得 AdamW 能更有效地实现正则化，并提升模型的泛化能力，因此被广泛应用于大语言模型的训练中。\n",
    "\n",
    "让我们通过训练一个 GPTModel 实例来实际操作看看，训练 10 个 epoch，使用 AdamW 优化器和之前定义的`train_model_simple`函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "069da1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.897, Val loss 9.951\n",
      "Ep 1 (Step 000005): Train loss 7.917, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.847, Val loss 7.044\n",
      "Ep 2 (Step 000015): Train loss 5.997, Val loss 6.604\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.659, Val loss 6.617\n",
      "Ep 3 (Step 000025): Train loss 5.363, Val loss 6.330\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.010, Val loss 6.281\n",
      "Ep 4 (Step 000035): Train loss 2.549, Val loss 6.227\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.834, Val loss 6.149\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.516, Val loss 6.156\n",
      "Ep 6 (Step 000050): Train loss 3.006, Val loss 6.144\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.575, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 1.757, Val loss 6.235\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 0.958, Val loss 6.251\n",
      "Ep 8 (Step 000070): Train loss 1.497, Val loss 6.262\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.796, Val loss 6.336\n",
      "Ep 9 (Step 000080): Train loss 0.639, Val loss 6.476\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.404, Val loss 6.504\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30c9f4",
   "metadata": {},
   "source": [
    "执行 `training_model_simple` 函数将开始训练过程，在 MacBook Air 或类似的笔记本电脑上完成约需 5 分钟。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0e90e",
   "metadata": {},
   "source": [
    "根据训练过程中的输出结果，训练损失显著下降，从 9.897 降到 0.404，模型的语言能力大幅提升。在训练初期，模型仅能在起始上下文后添加逗号（如“Every effort moves you,,,,,,,,,,,,”）或重复单词“and”。而在训练结束时，模型能够生成符合语法的文本。\n",
    "\n",
    "与训练集损失类似，我们可以看到验证集损失在开始时较高（9.951），随后在训练过程中下降。但它始终未能像训练集损失那样低，在第 10 个 epoch 后保持在 6.504。\n",
    "\n",
    "在更详细地讨论验证集损失之前，我们先创建一个简单的图表，将训练集和验证集损失并排展示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ba6b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()  # 创建与 y 轴共用的第二个 x 轴\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 用于对齐刻度的隐藏图形\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c827b7a",
   "metadata": {},
   "source": [
    "生成的训练损失和验证损失图表如图 5.12 所示。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.12.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.12 所示，训练损失和验证损失在第一个 epoch 开始时都有所改善。然而，从第二个 epoch 之后，损失开始出现分歧。验证损失远高于训练损失，这表明模型在训练数据上出现了过拟合。我们可以通过搜索生成的文本片段（例如“The Verdict”文件中的片段：“quite insensible to the irony”）来确认模型逐词记住了训练数据。\n",
    "\n",
    "这种记忆现象是预料之中的，因为我们使用了一个非常小的训练数据集，并且对模型进行了多轮训练。通常，我们会在更大的数据集上训练模型，并且只需训练一个 epoch 即可。\n",
    "\n",
    "> [!TIP]\n",
    ">\n",
    "> **个人思考：** 让我们基于 LLM 的原理来探讨一下为什么在一个较小的数据集上进行多轮训练，容易产生过拟合的现象？\n",
    ">\n",
    "> 1. **模型容量与数据集大小的匹配问题**\n",
    ">    + 大语言模型具有极高的参数容量，通常包含数百万甚至数十亿个参数。如此巨大的参数空间可以高度灵活地适应数据，使得模型能够“记住”每个样本的具体特征\n",
    ">    + 当数据集很小时，模型没有足够的多样性去学习广泛的模式，而是倾向于学习每个数据点的细节。经过多轮训练，模型会逐渐“记住”小数据集中每个样本的特征，从而导致过拟合。\n",
    "> 2. **多轮训练导致对数据集细节的过度学习**\n",
    ">    + 多轮训练意味着模型会反复接触相同的数据。这种重复使得模型逐渐适应数据集的特定模式，而不是学习一般化的规律。\n",
    ">    + 每次训练迭代都会使模型在数据集上拟合得更好，因此在训练数据上损失逐渐减小，但由于缺少新的数据，模型无法学习到通用模式，只会进一步记住训练样本的细节。\n",
    "> 3. **数据集的多样性不足**\n",
    ">    + 小数据集通常不能代表广泛的语言特征和分布，缺乏多样性。模型在小数据集上多轮训练，基本上是在有限的样本范围内形成模式，导致它对特定的训练样本依赖性过强。\n",
    ">    + 这种缺乏多样性的训练会使模型偏向训练数据的分布，难以适应实际应用中广泛的输入数据。\n",
    "> 4. **过拟合与模型泛化能力的矛盾**\n",
    ">    + 过拟合本质上是模型在训练数据上的表现优异，但在未见过的数据上表现较差。大语言模型的训练目标是提高其泛化能力，即能在更广泛的分布上生成有意义的文本。\n",
    ">    + 当数据集非常小且多轮训练时，模型会对数据的细节和噪声进行过度拟合，这会导致模型在测试数据或实际应用中表现不佳，因为它无法应对新的、不同分布的输入。\n",
    ">\n",
    ">\n",
    "\n",
    "如前所述，感兴趣的读者可以尝试用 Project Gutenberg 中 60,000 本公共领域书籍来训练模型，这种情况下不会出现过拟合现象。详细信息见附录 B。\n",
    "\n",
    "在接下来的部分（如图 5.13 所示），我们将探讨 LLM 使用的采样方法，这些方法可以减轻记忆效应，从而生成更具新意的文本。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.13.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.13 所示，下一节将介绍适用于 LLM 的文本生成策略，以减少训练数据的记忆倾向，提升 LLM 生成文本的原创性。之后我们还会讨论权重的加载与保存，以及从 OpenAI 的 GPT 模型加载预训练权重。\n",
    "\n",
    "---\n",
    "\n",
    "## 5.3 通过解码策略控制生成结果的随机性\n",
    "\n",
    "本节将介绍文本生成策略（也称为解码策略），用于生成更具原创性的文本。首先，我们将简要回顾前一章中的`generate_text_simple`函数，该函数已在本章前面用于生成和打印样本。然后，我们会讲解两种改进方法：`temperature scaling`和 `top-k 采样`。\n",
    "\n",
    "首先，我们将模型从 GPU 转移回 CPU，因为相对较小的模型在推理时不需要使用 GPU。另外，在训练结束后，我们会将模型切换到评估模式，以关闭 dropout 等随机组件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "caa12899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c51ef",
   "metadata": {},
   "source": [
    "接下来，将 GPTModel 的实例（model）传入 generate_text_simple 函数，该函数使用 LLM 一次生成一个 token："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb0a0b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd608010",
   "metadata": {},
   "source": [
    "如 5.1.2 节中所述，在生成过程中的每一步，都会选取词汇表中概率得分最高的 token 作为生成的 token。\n",
    "\n",
    "接下来介绍两种控制生成文本随机性和多样性的方法：`temperature scaling`和`top-k sampling`。\n",
    "\n",
    "\n",
    "\n",
    "### 5.3.1 Temperature scaling\n",
    "\n",
    "本节将介绍`temperature scaling`，这是一种在生成下一个词时加入概率选择的技术。\n",
    "\n",
    "之前，在 `generate_text_simple` 函数中，我们总是用 `torch.argmax` 选择概率最高的 token 作为下一个词，这也叫做贪心解码。为了生成更加多样化的文本，可以将 `argmax` 替换为一种从概率分布中进行采样的函数（这里，概率分布是指模型在每一步为每个词汇生成的概率得分）。\n",
    "\n",
    "为了用具体的例子说明概率采样，我们将简要讨论下一词生成过程，并用一个非常小的词汇表来进行示例演示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7b3b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a16c01",
   "metadata": {},
   "source": [
    "接下来，假设给 LLM 一个初始上下文‘every effort moves you’，并生成下一个 token 的 logits 分数（如下所示）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c5632cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ac8ab",
   "metadata": {},
   "source": [
    "接着在 `generate_text_simple` 函数中，通过 softmax 函数将 logits 转化为概率，并通过 argmax 函数得到生成的 token 的 ID，最后通过逆词汇表将其映射回文本（可以回顾上一章）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc88a584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf46fce",
   "metadata": {},
   "source": [
    "由于第四个位置的 logit 值最大，相应地，Softmax 归一化后的概率分数也在该位置上最大，因此生成的下一个词就是这个位置对应的词。\n",
    "\n",
    "为了实现概率采样过程，现在可以用 PyTorch 中的 multinomial 函数代替 argmax："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca8a0ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a54b62",
   "metadata": {},
   "source": [
    "输出依然是“forward”，这和之前一样。这是为什么？\n",
    "multinomial 函数根据每个 token 的概率得分来采样下一个 token。换句话说，“forward” 依然是最有可能的 token，因此大多数情况下会被 multinomial 选中，但并不是每次都选中。为了演示这一点，我们可以实现一个函数，重复采样 1000 次："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72bd40ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a8bfb",
   "metadata": {},
   "source": [
    "从输出结果可以看出，单词‘forward’在生成过程中被采样的次数最多（在 1000 次生成中出现了 582 次），但‘closer’、‘inches’和‘toward’等其他词语也偶尔会被采样到。这意味着，如果在生成函数 generate_and_print_sample 中将 argmax 替换为 multinomial，模型有时会生成类似‘every effort moves you toward’、‘every effort moves you inches’和‘every effort moves you closer’这样的句子，而不是固定生成‘every effort moves you forward’。\n",
    "\n",
    "我们可以通过一种称为`temperature scaling`的方法进一步控制分布和选择过程，所谓`temperature scaling`，其实就是将 logits 除以一个大于 0 的数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfeeeb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "#Temperatures greater than 1 result in more uniformly distributed token probabilities, and Temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions. Let's illustrate this by plotting the original probabilities alongside probabilities scaled with different temperature values:\n",
    "# 原始、较低和较高置信度\n",
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2788d8bf",
   "metadata": {},
   "source": [
    "图 5.14 展示了生成的图表:\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.14.png\" width=\"75%\" />\n",
    "\n",
    "当 temperature 取 1 时，logits 在传递给 softmax 函数之前会除以 1，计算概率得分。这意味着，temperature 为 1 时相当于不进行任何缩放。在这种情况下，模型将根据原始的 softmax 概率，通过 PyTorch 中的`multinomial`函数来选择 token。\n",
    "\n",
    "如图 5.14 所示，当 temperature 设置为非常小的值（如 0.1）时，生成的分布会更加尖锐，因此`multinomial`函数几乎总是选择最可能的 token（这里是 ‘forward’），其行为接近 argmax 函数。相反，当 temperature 设置为 5 时，生成的分布更接近均匀分布，其他 token 被选中的频率更高。这种情况下，生成的文本多样性增加，但也更可能出现无意义的内容。例如，temperature 设置为 5 时，模型生成类似 ‘every effort moves you pizza’ 的文本概率大约为 4%。\n",
    "\n",
    "> [!TIP]\n",
    ">\n",
    "> **个人思考：** 为什么 temperature 值非常小时，生成的概率分布会更加尖锐，越大时，概率分布会更加均匀，文中只是说了结论，没有说过程。\n",
    ">\n",
    "> **temperature** 参数被引入到 softmax 函数中，用于缩放 logits，从而控制输出的概率分布。当引入 temperature 后，softmax 函数的公式变为：\n",
    ">\n",
    "> $$ P\\left(x_{i}\\right)=\\frac{\\exp \\left(\\frac{z_{i}}{T}\\right)}{\\sum_{j} \\exp \\left(\\frac{z_{j}}{T}\\right)} $$\n",
    ">\n",
    "> 1. **当 T>1**\n",
    ">    所有 logits 被除以 T，缩放后，差异变小。由于 exp 函数的敏感性较高，这意味着 logits 值的差异被“压平”，使得最优词的概率降低，而其他次优词的概率提高。输出的概率分布变得更加均匀，再结合multinomial函数，可以使生成结果更加多样化，但同时也降低了生成结果的确定性。\n",
    ">\n",
    "> 2. **当 T<1**\n",
    ">\n",
    ">    logits 除以 T 后会被放大，差异变得更加显著。softmax 函数会使最高 logit 对应的词语的概率变得更高，其他词语的概率更低。这导致输出的概率分布更加集中，模型更倾向于选择概率最大的词，从而提高了生成结果的确定性。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **练习 5.1**\n",
    ">\n",
    "> 使用 `print_sampled_tokens` 函数，打印在图 5.14 所示 temperature 值下缩放的 Softmax 概率的采样频率。在每种情况下，单词“pizza”被采样的频率是多少？你能想到一种更快、更准确的方法来确定“pizza”被采样的频率吗？\n",
    "\n",
    "\n",
    "\n",
    "### 5.3.2 Top-k 采样\n",
    "\n",
    "在前一节中，我们实现了一种结合`temperature scaling`的概率采样方法来增加生成内容的多样性。我们发现，较高的 temperature 值会使下一词的概率分布更均匀，从而降低模型反复选择最可能词的概率，这样可以生成更多样化的内容，使生成过程探索那些概率较低但可能更有趣和创意的路径。不过，这种方法的一个缺点是，有时会导致生成语法不正确或完全不合逻辑的内容，比如 \"every effort moves you pizza\"。\n",
    "\n",
    "在本节中，我们引入了另一种称为`top-k 采样`的概念，当与概率采样和`temperature scaling`结合使用时，可以提升文本生成效果。\n",
    "\n",
    "在 top-k 采样中，我们可以将采样限制在最有可能的前 k 个 token 内，并通过将其他 token 的概率设为零，将它们排除在选择之外，如图 5.15 所示。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.15.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.15 所示，将所有未选中的 logits 替换为负无穷（-inf），这样在计算 Softmax 时，非 top-k 的 token 的概率为 0，剩下的概率之和为 1。（细心的读者可能记得，我们在第 3 章的因果注意力模块中使用过这种掩码技巧。）\n",
    "\n",
    "接下来让我们通过代码实现 Figure 5.15 中描述的 top-k 过程，首先选出 logits 值最大的那些 token："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c676f20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2015ba6",
   "metadata": {},
   "source": [
    "接下来，我们应用 PyTorch 的 where 函数，将非 top-3 的 token 的 logit 值设为负无穷大（-inf）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76324c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    # 识别出小于 top 3 最小值的 logits\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    # 将这些较小的 logits 赋值为负无穷大\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    # 保留所有其他 token 的原始 logits\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52c1e4",
   "metadata": {},
   "source": [
    "最后，应用 softmax 函数将其转化为下一词的概率分布："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e50c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c5881b",
   "metadata": {},
   "source": [
    "我们现在可以应用`temperature scaling` 和`multinomial`函数来进行概率采样，从这 3 个非零概率得分中选择下一个 token。在下一节中，我们将通过修改文本生成函数来实现此操作。\n",
    "\n",
    "\n",
    "\n",
    "### 5.3.3 对文本生成函数进行调整\n",
    "\n",
    "前两节介绍了两种增加 LLM 生成文本多样性的概念：`temperature scaling`和`top-k 采样`。本节中，我们将这两个概念整合并加入到之前用于生成文本的`generate_simple`函数中，从而创建一个新的`generate`函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd0286e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.4 A modified text generation function with more diversity\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=1.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 如果 top_k 不为 None，则执行 top-k 采样\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        # 如果 temperature 大于 0.0，则执行 temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        # 如果 temperature 为 0.0，则执行贪婪的下一个 token 选择\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        # 如果遇到序列结束 token 且指定了 eos_id，则提前停止生成\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb5519",
   "metadata": {},
   "source": [
    "现在来看看这个新的`generate`函数的实际效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17493972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand to work on surprise, a one of us had gone with random-\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575325e0",
   "metadata": {},
   "source": [
    "正如我们所见，当前生成的文本与之前在 5.3 节开头用 `generate_simple` 函数生成的文本有很大不同（例如那句\"Every effort moves you know,\" was one of the axioms he laid...!\"），而后者是模型从训练集中记忆的一段话。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **练习 5.2**\n",
    ">\n",
    "> 尝试不同的 temperature 和 top-k 设置。根据你的观察，你能想到哪些应用场景适合较低的 temperature 和 top-k 设置吗？反之，哪些应用场景适合较高的 temperature 和 top-k 设置？（建议在本章末加载 OpenAI 的预训练权重后，再次进行此练习）\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **练习 5.3**\n",
    ">\n",
    "> generate 函数有哪些不同的设置组合可以强制生成确定性行为，即禁用随机采样，使其输出始终一致，类似于 generate_simple 函数？\n",
    ">\n",
    "> 到目前为止，我们已介绍了如何预训练 LLM 并使用其生成文本。本章最后两节将讨论如何保存和加载训练好的 LLM，以及如何加载 OpenAI 的预训练权重。\n",
    "\n",
    "---\n",
    "\n",
    "## 5.4 在 PyTorch 中加载和保存模型权重\n",
    "\n",
    "在本章中，我们讨论了如何数值化评估训练进度，以及从零开始预训练 LLM。尽管模型和数据集都相对较小，这次练习依然展示了预训练 LLM 的高昂成本。因此，能够保存 LLM 以避免每次在新会话中使用时都重新训练显得尤为重要。\n",
    "\n",
    "如图 5.16 的章节概览所示，本节将介绍如何保存和加载预训练模型。然后，在接下来的部分中，我们将从 OpenAI 加载一个更强大的预训练 GPT 模型到我们的 GPTModel 实例中。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.16.png\" width=\"75%\" />\n",
    "\n",
    "幸运的是，保存 PyTorch 模型相对简单。推荐的做法是保存模型的 `state_dict`（状态字典），这是一个字典，用于将模型的每一层映射到其对应的参数上，可以通过 `torch.save` 函数来实现，代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b54fce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8db9f5",
   "metadata": {},
   "source": [
    "在以上代码中，`model.pth`是用于保存 `state_dict` 的文件名。`.pth` 是 PyTorch 文件的惯用扩展名，但实际上也可以使用其他扩展名。\n",
    "\n",
    "使用 `state_dict` 保存模型权重后，可以将权重加载到新的 GPTModel 模型实例中，具体操作如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18cfc8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e891720",
   "metadata": {},
   "source": [
    "正如第 4 章所讨论的，dropout 通过在训练过程中随机“丢弃”某些神经元，以防止模型过拟合。然而，在推理阶段，我们不希望随机丢弃网络中学到的任何信息。通过使用 `model.eval()`，模型会切换到推理阶段的评估模式，从而禁用 dropout 层。\n",
    "\n",
    "如果计划稍后继续预训练模型（例如使用本章之前定义的 train_model_simple 函数），那么建议同时保存优化器状态。\n",
    "\n",
    "AdamW 等自适应优化器会为每个模型参数存储额外信息。AdamW 使用历史数据动态调整每个模型参数的学习率。没有这些信息时，优化器会重置，模型可能无法有效学习，甚至无法正确收敛，进而失去生成连贯文本的能力。可以使用 `torch.save` 保存模型和优化器的状态，方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81eadaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db41450",
   "metadata": {},
   "source": [
    "接下来，我们可以按以下步骤恢复模型和优化器的状态：首先通过 `torch.load` 加载保存的数据，然后使用 `load_state_dict` 方法恢复状态："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ab64d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99267200",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    ">\n",
    "> **练习 5.4**\n",
    ">\n",
    "> 保存权重后，在新的 Python 会话中加载模型和优化器，使用 train_model_simple 函数继续进行 1 个 epoch 的预训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bcd5677c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.311, Val loss 6.574\n",
      "Ep 1 (Step 000005): Train loss 0.142, Val loss 6.648\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=1, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f023c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## 5.5 从 OpenAI 加载预训练权重\n",
    "\n",
    "之前，我们为了教学目的，使用有限的数据集（包含一本短篇小说集）训练了一个小型 GPT-2 模型，这样可以专注于讲解 LLM 的基本原理，而无需耗费大量时间和计算资源。\n",
    "\n",
    "OpenAI 公开了 GPT-2 模型的权重，使我们不必投入数十万甚至数百万美元自行在大规模语料上重新训练模型。\n",
    "\n",
    "在本节的余下部分，我们将把这些权重加载到 GPTModel 类中，并利用该模型进行文本生成。这里的权重是指存储在 PyTorch 的 Linear 和 Embedding 层的 `.weight`属性中的权重参数（在训练模型时，我们可以通过`model.parameters() `访问这些权重）。\n",
    "\n",
    "在后续章节中，我们将复用这些预训练权重，对模型进行微调以用于文本分类任务，并遵循类似 ChatGPT 的指令。\n",
    "\n",
    "请注意，OpenAI 最初使用 TensorFlow 来保存 GPT-2 的权重，因此在 Python 中加载这些权重需要安装 TensorFlow。另外，以下代码将使用进度条工具 tqdm 来跟踪下载进度，也需要提前安装。\n",
    "\n",
    "请在终端中执行以下命令来安装所需的库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78856b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow>=2.15.0 tqdm>=4.66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaee9b6",
   "metadata": {},
   "source": [
    "由于下载代码篇幅较长，主要是样板代码，因此本章不会浪费篇幅详细讨论。读者可以直接从本章的在线资源库下载 `gpt_download.py` 模块:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac9ee186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x338291990>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df50928",
   "metadata": {},
   "source": [
    "接下来，在将此文件下载到本地目录后，建议读者简单查看文件内容，确保文件已正确保存并包含有效的 Python 代码。\n",
    "\n",
    "我们现在可以从 `gpt_download.py` 文件中导入 `download_and_load_gpt2` 函数，从而将 GPT-2 的架构设置（settings）和权重参数（params）加载到 Python 会话中：\n",
    "\n",
    "> 如何不能科学上网，可以从[魔搭平台](https://www.modelscope.cn/models/horiki/gpt2-124M/summary)进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "99ccd6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 35.9kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 572kiB/s] \n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 30.7kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [16:48<00:00, 494kiB/s]    \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 1.37MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 412kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 374kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "from scratch_llm.code.gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba17c30",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    ">\n",
    "> **最新下载说明**\n",
    ">\n",
    "> 如果下载代码无法正常工作，可能是由于网络连接不稳定、服务器问题，或者 OpenAI 共享 GPT-2 模型权重的方式发生了变化。请访问本章节的在线代码库（https://github.com/rasbt/LLMs-from-scratch），以获取更新的操作说明。如有其他问题，也可在 Manning 论坛中提问。\n",
    "\n",
    "代码执行完成后，查看 `settings` 和 `params` 的内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93029891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a89e42a",
   "metadata": {},
   "source": [
    "`settings` 和 `params` 都是 Python 字典。`settings` 字典存储了 LLM 的架构设置，与我们之前手动定义的 `GPT_CONFIG_124M` 设置类似；`params` 字典则包含实际的权重张量。注意，我们只打印了字典的键，因为打印整个权重内容会占用太多屏幕空间。不过，我们可以通过`print(params)` 打印整个字典，或使用特定的字典键选择对应张量进行查看，例如嵌入层的权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4cb14a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585301ee",
   "metadata": {},
   "source": [
    "我们通过 `download_and_load_gpt2(model_size=\"124M\", ...)` 加载了最小的 GPT-2 模型权重。此外，OpenAI 还提供了更大规模模型的权重，包括 \"355M\"、\"774M\" 和 \"1558M\" 等。尽管模型规模不同，但其整体架构是相同的，如图 5.17 所示。\n",
    "\n",
    "<img src=\"../image/chapter5/figure5.17.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.17 所示，不同大小的 GPT-2 模型在总体架构上保持一致，但注意力头和 Transformer 模块等组件的重复次数以及嵌入维度大小有所不同。本章的剩余代码也会兼容这些更大的模型。\n",
    "\n",
    "在将 GPT-2 模型的权重加载到 Python 后，我们还需要将这些权重从 `settings` 和 `params` 字典转移到 GPTModel 实例中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ede9abca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we create a dictionary that lists the differences between the different GPT model sizes, as explained in Figure 5.17:\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "# Suppose we are interested in loading the smallest model, \"gpt2-small (124M)\". We can use the corresponding settings from the model_configs table able to update our full-length GPT_CONFIG_124M we defined and used earlier throughout the chapter as follows:\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e146b",
   "metadata": {},
   "source": [
    "细心的读者可能记得，我们之前设置的 token 长度是 256，但 OpenAI 的原始 GPT-2 模型使用的是 1,024 的 token 长度，因此我们需要相应地更新 NEW_CONFIG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67d717ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd756170",
   "metadata": {},
   "source": [
    "此外，OpenAI 在多头注意力模块的线性层中使用了偏置向量，以实现查询（query）、键（key）和值（value）矩阵的计算。偏置向量在现代 LLM 中已不再常用，因为它们对提升模型性能没有帮助，因而不再必要。然而，由于我们使用的是预训练权重，为了保持一致性，仍需启用这些偏置向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63e7cf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "# We can now use the updated NEW_CONFIG dictionary to initialize a new GPTModel instance:\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b4a03",
   "metadata": {},
   "source": [
    "默认情况下，GPTModel 实例会使用随机权重进行预训练。而使用 OpenAI 的模型权重的最后一步是将 `params` 字典中加载的权重覆盖这些随机权重。\n",
    "\n",
    "为此，我们首先来定义一个简单的`assign`工具函数，用于检查两个张量或数组（左侧和右侧）的维度或形状是否一致，并将右侧张量作为可训练的 PyTorch 参数返回："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e51812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8601d7b",
   "metadata": {},
   "source": [
    "接下来，我们定义一个名为 `load_weights_into_gpt` 的函数，用于将 `params` 字典中的权重加载到 GPT 模型实例中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "350a0ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.5 Loading OpenAI weights into our GPT model code\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    # 将模型的位置嵌入和token 嵌入的权重设置为 params 中指定的值\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    # 遍历模型中的每个 Transformer 模块\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        # 使用 np.split 函数将注意力和偏置权重分为三等份，分别用于查询、键和值组件\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        # 注意力模块的偏置权重\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        # 输出投影层的权重\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # 前馈神经网络的权重\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # 归一化层的权重\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    # 最终归一化层的权重\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    # OpenAI 的原始 GPT-2 模型在输出层中复用了 token 嵌入的权重，以减少参数总量，这一概念称为权重共享\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d43ec",
   "metadata": {},
   "source": [
    "在 `load_weights_into_gpt` 函数中，我们需要将 OpenAI 实现中的权重与自定义的 GPTModel 实现进行精确匹配。举个例子，OpenAI 将第一个 Transformer 模块的输出投影层权重存储在 `params[\"blocks\"][0][\"attn\"][\"c_proj\"][\"w\"]` 中。而在我们的实现中，这个权重对应于 `gpt.trf_blocks[b].att.out_proj.weight`，其中 `gpt` 是一个 GPTModel 实例。\n",
    "\n",
    "在开发 `load_weights_into_gpt` 函数时，由于 OpenAI 的命名规范和我们的略有不同，我们进行了大量的尝试。幸运的是，`assign` 函数会在张量维度不匹配时发出警告。此外，如果这个函数有错误，我们会发现生成的 GPT 模型无法生成连贯的文本，从而识别出问题。\n",
    "\n",
    "我们暂时不在实际操作中尝试 `load_weights_into_gpt`，而是直接将 OpenAI 模型的权重加载到我们自己的 `GPTModel` 实例 `gpt` 中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a587666f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3bc88",
   "metadata": {},
   "source": [
    "如果模型加载成功，就可以使用之前的 `generate` 函数生成新文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "607d88dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b9b9a",
   "metadata": {},
   "source": [
    "我们可以确认模型权重已正确加载，因为模型能够生成连贯的文本；在这个过程中，哪怕一个小错误都会导致模型生成失败。\n",
    "\n",
    "在接下来的章节中，我们将进一步使用该预训练模型，并对其进行微调，使其能够进行文本分类和指令执行。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **练习 5.5**\n",
    ">\n",
    "> 使用 OpenAI 预训练权重的 GPT 模型在‘The Verdict’数据集上计算训练集和验证集的损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90ca1842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.664, Val loss 6.962\n",
      "Ep 1 (Step 000005): Train loss 0.388, Val loss 6.776\n",
      "Every effort moves you?\" \"Oh, pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"  He placed them at my elbow and continued to wander up and down the room, stopping now\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=1, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556d53c",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    ">\n",
    "> **练习 5.6**\n",
    ">\n",
    "> 建议读者尝试不同规模的 GPT-2 模型，例如最大规模的 1558M 参数模型，并与本章加载的 124M 模型的生成效果进行比较。\n",
    "\n",
    "---\n",
    "\n",
    "## 5.6 本章摘要\n",
    "\n",
    "+ 大语言模型在生成文本时，逐个生成 token。\n",
    "+ 默认情况下，模型通过将输出转换为概率分数，并选择其中概率最高的 token 来生成下一个 token，这种方式称为“贪心解码”。\n",
    "+ 通过概率采样和`temperature scaling`，可以影响生成文本的多样性和连贯性。\n",
    "+ 训练集和验证集的损失可以用来评估 LLM 在训练过程中生成文本的质量。\n",
    "+ 预训练 LLM 的过程就是通过调整模型权重来最小化训练损失。\n",
    "+ LLM 的训练循环是深度学习中的标准流程，通常使用交叉熵损失和 AdamW 优化器。\n",
    "+ 在大规模文本数据集上预训练 LLM 非常耗费时间和资源，因此可以加载 OpenAI 提供的开源预训练权重，作为自行预训练模型的替代方案。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
